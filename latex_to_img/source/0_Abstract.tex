Generating meaningful statistical summaries without compromising individual privacy is a central challenge in data analysis. Local Differential Privacy (LDP) addresses this by allowing users to perturb their data before aggregation, but existing frequency estimation protocols are diverse and lack a common framework for rigorous comparison. This paper provides a unified view of frequency estimation under the framework of Pure LDP, surveying three representative protocols: k-Randomized Response (kRR), Optimized Unary Encoding (OUE), and Optimized Local Hashing (OLH). We analyze the trade-offs inherent in these methods, demonstrating that while kRR suffers from high variance in large domains, OLH achieves optimal utility with significantly reduced communication costs. Furthermore, we evaluate the security of these protocols against data poisoning, specifically the Maximal Gain Attack, where adversaries inject fake users to skew frequency estimates. Our analysis reveals a fundamental privacy-security paradox: stronger privacy guarantees (lower $\epsilon$) necessitate higher noise levels, which inadvertently mask malicious inputs and amplify the effectiveness of poisoning attacks. We quantify this vulnerability, showing that while OUE and OLH provide stable resistance independent of domain size, kRR becomes critically insecure as the domain grows.