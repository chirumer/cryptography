{
  "source_pdf": "LDP_Freq_Est.pdf",
  "relative_pdf_path": "papers/LDP_Freq_Est.pdf",
  "num_pages": 19,
  "pages": [
    {
      "page_number": 1,
      "text": "This paper is included in the Proceedings of the \n26th USENIX Security Symposium\nAugust 16–18, 2017 • Vancouver, BC, Canada\nISBN 978-1-931971-40 -9\nOpen access to the Proceedings of the \n26th USENIX Security Symposium \nis sponsored by USENIX\nLocally Differentially Private Protocols  \nfor Frequency Estimation\nTianhao Wang, Jeremiah Blocki, and Ninghui Li, Purdue University;  \nSomesh Jha, University of Wisconsin Madison\nhttps://www.usenix.org/conference/usenixsecurity17/technical-sessions/presentation/wang-tianhao"
    },
    {
      "page_number": 2,
      "text": "Locally Differentially Private Protocols for Frequency Estimation\nTianhao Wang, Jeremiah Blocki, Ninghui Li\nPurdue University\nSomesh Jha\nUniversity of Wisconsin-Madison\nAbstract\nProtocols satisfying Local Differential Privacy (LDP) en-\nable parties to collect aggregate information about a pop-\nulation while protecting each user’s privacy, without re-\nlying on a trusted third party. LDP protocols (such as\nGoogle’s RAPPOR) have been deployed in real-world\nscenarios. In these protocols, a user encodes his pri-\nvate information and perturbs the encoded value locally\nbefore sending it to an aggregator, who combines val-\nues that users contribute to infer statistics about the pop-\nulation. In this paper, we introduce a framework that\ngeneralizes several LDP protocols proposed in the liter-\nature. Our framework yields a simple and fast aggre-\ngation algorithm, whose accuracy can be precisely ana-\nlyzed. Our in-depth analysis enables us to choose opti-\nmal parameters, resulting in two new protocols (i.e., Op-\ntimized Unary Encoding and Optimized Local Hashing)\nthat provide better utility than protocols previously pro-\nposed. We present precise conditions for when each pro-\nposed protocol should be used, and perform experiments\nthat demonstrate the advantage of our proposed proto-\ncols.\n1 Introduction\nDifferential privacy [10, 11] has been increasingly ac-\ncepted as the de facto standard for data privacy in the\nresearch community. While many differentially private\nalgorithms have been developed for data publishing and\nanalysis [12, 19], there have been few deployments of\nsuch techniques. Recently, techniques for satisfying dif-\nferential privacy (DP) in the local setting, which we\ncall LDP, have been deployed. Such techniques enable\ngathering of statistics while preserving privacy of every\nuser, without relying on trust in a single data curator.\nFor example, researchers from Google developed RAP-\nPOR [13, 16], which is included as part of Chrome. It\nenables Google to collect users’ answers to questions\nsuch as the default homepage of the browser, the default\nsearch engine, and so on, to understand the unwanted\nor malicious hijacking of user settings. Apple [1] also\nuses similar methods to help with predictions of spelling\nand other things, but the details of the algorithm are not\npublic yet. Samsung proposed a similar system [21]\nwhich enables collection of not only categorical answers\n(e.g., screen resolution) but also numerical answers (e.g.,\ntime of usage, battery volume), although it is not clear\nwhether this has been deployed by Samsung.\nA basic goal in the LDP setting is frequency estima-\ntion. A protocol for doing this can be broken down\ninto following steps: For each question, each user en-\ncodes his or her answer (called input) into a specific for-\nmat, randomizes the encoded value to get an output, and\nthen sends the output to the aggregator, who then aggre-\ngates and decodes the reported values to obtain, for each\nvalue of interest, an estimate of how many users have that\nvalue. With improvement on the basic task of frequency\nestimation, solutions to more complex problems that rely\non it, such as heavy hitter identification, frequent itemset\nmining, can also be improved.\nWe introduce a framework for what we call “pure”\nLDP protocols, which has a nice symmetric property.\nWe introduce a simple, generic aggregation and decod-\ning technique that works for all pure LDP protocols, and\nprove that this technique results in an unbiased estimate.\nWe also present a formula for the variance of the esti-\nmate. Most existing protocols fit our proposed frame-\nwork. The framework also enables us to precisely ana-\nlyze and compare the accuracy of different protocols, and\ngeneralize and optimize them. For example, we show\nthat the Basic RAPPOR protocol [13], which essentially\nuses unary encoding of input, chooses sub-optimal pa-\nrameters for the randomization step. Optimizing the pa-\nrameters results in what we call the Optimized Unary\nEncoding (OUE) protocol, which has significantly bet-\nter accuracy.\nProtocols based on unary encoding require Θ(d) com-\nUSENIX Association 26th USENIX Security Symposium    729"
    },
    {
      "page_number": 3,
      "text": "munication cost, where d is the number of possible in-\nput values, and can be very large (or even unbounded)\nfor some applications. The RAPPOR protocol uses a\nBloom filter encoding to reduce the communication cost;\nhowever, this comes with a cost of decreasing accuracy\nas well as increasing computation cost for aggregation\nand decoding. The random matrix projection-based ap-\nproach introduced in [6] has Θ(logn) communication\ncost (where n is the number of users); however, its accu-\nracy is unsatisfactory. We observe that in our framework\nthis protocol can be interpreted as binary local hash-\ning. Generalizing this and optimizing the parameters re-\nsults in a new Optimized Local Hashing (OLH) protocol,\nwhich provides much better accuracy while still requir-\ning Θ(logn) communication cost. The variance of OLH\nis orders of magnitude smaller than the previous meth-\nods, for ε values used in RAPPOR’s implementation. In-\nterestingly, OLH has the same error variance as OUE;\nthus it reduces communication cost at no cost of utility.\nWith LDP, it is possible to collect data that was in-\naccessible because of privacy issues. Moreover, the in-\ncreased amount of data will significantly improve the\nperformance of some learning tasks. Understanding cus-\ntomer statistics help cloud server and software platform\noperators to better understand the needs of populations\nand offer more effective and reliable services. Such\nprivacy-preserving crowd-sourced statistics are also use-\nful for providing better security while maintaining a level\nof privacy. For example, in [13], it is demonstrated\nthat such techniques can be applied to collecting win-\ndows process names and Chrome homepages to discover\nmalware processes and unexpected default homepages\n(which could be malicious).\nOur paper makes the following contributions:\n• We introduce a framework for “pure” LDP proto-\ncols, and develop a simple, generic aggregation and\ndecoding technique that works for all such proto-\ncols. This framework enables us to analyze, gener-\nalize, and optimize different LDP protocols.\n• We introduce the Optimized Local Hashing (OLH)\nprotocol, which has low communication cost and\nprovides much better accuracy than existing proto-\ncols. For ε ≈ 4, which was used in the RAPPOR\nimplementation, the variance of OLH’s estimation\nis 1/2 that of RAPPOR, and close to 1 /14 that of\nRandom Matrix Projection [6]. Systems using LDP\nas a primitive could benefit significantly by adopt-\ning improved LDP protocols like OLH.\nRoadmap. In Section 2, we describe existing proto-\ncols from [13, 6]. We then present our framework for\npure LDP protocols in Section 3, apply it to study LDP\nprotocols in Section 4, and compare different LDP proto-\ncols in Section 5. We show experimental results in Sec-\ntion 6. We review related work in Section 7, discuss in\nSection 8, and conclude in Section 9.\n2 Background and Existing Protocols\nThe notion of differential privacy was originally intro-\nduced for the setting where there is a trusted data cu-\nrator, who gathers data from individual users, processes\nthe data in a way that satisfies DP, and then publishes the\nresults. Intuitively, the DP notion requires that any sin-\ngle element in a dataset has only a limited impact on the\noutput.\nDefinition 1 (Differential Privacy) An algorithm A\nsatisfies ε-differential privacy ( ε-DP), where ε ≥ 0, if\nand only if for any datasets D and D ′ that differ in one\nelement, we have\n∀t ∈Range(A) : Pr[A(D) =t] ≤ eε Pr\n[\nA(D′) =t\n]\n,\nwhere Range(A) denotes the set of all possible outputs\nof the algorithm A.\n2.1 Local Differential Privacy Protocols\nIn the local setting, there is no trusted third party. Anag-\ngregator wants to gather information from users. Users\nare willing to help the aggregator, but do not fully trust\nthe aggregator for privacy. For the sake of privacy, each\nuser perturbs her own data before sending it to the aggre-\ngator (via a secure channel). For this paper, we consider\nthat each user has a single value v, which can be viewed\nas the user’s answer to a given question. The aggrega-\ntor aims to find out the frequencies of values among the\npopulation. Such a data collection protocol consists of\nthe following algorithms:\n• Encode is executed by each user. The algorithm\ntakes an input value v and outputs an encoded value\nx.\n• Perturb, which takes an encoded value x and out-\nputs y. Each user with value v reports y =\nPerturb(Encode(v)). For compactness, we use\nPE(·) to denote the composition of the encod-\ning and perturbation algorithms, i.e., PE(·) =\nPerturb(Encode(·)). PE(·) should satisfy ε-local\ndifferential privacy, as defined below.\n• Aggregate is executed by the aggregator; it takes all\nthe reported values, and outputs aggregated infor-\nmation.\nDefinition 2 (Local Differential Privacy) An algo-\nrithm A satisfies ε-local differential privacy ( ε-LDP),\n730    26th USENIX Security Symposium USENIX Association"
    },
    {
      "page_number": 4,
      "text": "where ε ≥ 0, if and only if for any input v 1 and v2, we\nhave\n∀y ∈ Range(A) : Pr[A(v1) =y] ≤ eε Pr[A(v2) =y],\nwhere Range(A) denotes the set of all possible outputs\nof the algorithm A.\nThis notion is related to randomized response [24],\nwhich is a decades-old technique in social science to col-\nlect statistical information about embarrassing or illegal\nbehavior. To report a single bit by random response, one\nreports the true value with probabilityp and the flip of the\ntrue value with probability 1−p. This satisfies\n(\nln p\n1−p\n)\n-\nLDP.\nComparing to the setting that requires a trusted data\ncurator, the local setting offers a stronger level of pro-\ntection, because the aggregator sees only perturbed data.\nEven if the aggregator is malicious and colludes with all\nother participants, one individual’s private data is still\nprotected according to the guarantee of LDP.\nProblem Definition and Notations. There are n users.\nEach user j has one value vj and reports once. We use d\nto denote the size of the domain of the values the users\nhave, and [d] to denote the set {1,2,..., d}. Without loss\nof generality, we assume the input domain is [d]. The\nmost basic goal of Aggregate is frequency estimation,\ni.e., estimate, for a given value i ∈ [d], how many users\nhave the value i. Other goals have also been considered\nin the literature. One goal is, when d is very large, iden-\ntify values in [d] that are frequent, without going through\nevery value in [d] [16, 6]. In this paper, we focus on fre-\nquency estimation. This is the most basic primitive and is\na necessary building block for all other goals. Improving\nthis will improve effectiveness of other protocols.\n2.2 Basic RAPPOR\nRAPPOR [13] is designed to enable longitudinal collec-\ntions, where the collection happens multiple times. In-\ndeed, Chrome’s implementation of RAPPOR [3] collects\nanswers to some questions once every 30 minutes. Two\nprotocols, Basic RAPPOR and RAPPOR, are proposed\nin [13]. We first describe Basic RAPPOR.\nEncoding. Encode(v) =B0, where B0 is a length-d bi-\nnary vector such that B0[v] =1 and B0[i] =0 for i ̸= v.\nWe call this Unary Encoding.\nPerturbation. Perturb(B0) consists of two steps:\nStep 1: Permanent randomized response: Generate B1\nsuch that:\nPr[B1[i] =1] =\n{\n1 − 1\n2 f , if B0[i] =1,\n1\n2 f , if B0[i] =0.\nRAPPOR’s implementation uses f = 1/2 and f = 1/4.\nNote that this randomization is symmetric in the sense\nthat Pr[B1[i] =1|B0[i] =1] =Pr[B1[i] =0|B0[i] =0] =\n1 − 1\n2 f ; that is, the probability that a bit of 1 is preserved\nequals the probability that a bit of 0 is preserved. This\nstep is carried out only once for each value v that the\nuser has.\nStep 2: Instantaneous randomized response: Report B2\nsuch that:\nPr[B2[i] =1] =\n{\np, if B1[i] =1,\nq, if B1[i] =0.\nThis step is carried out each time a user reports the value.\nThat is, B1 will be perturbed to generate differentB2’s for\neach reporting. RAPPOR’s implementation [5] uses p =\n0.75 and q = 0.25, and is hence also symmetric because\np +q = 1.\nWe note that as both steps are symmetric, their com-\nbined effect can also be modeled by a symmetric ran-\ndomization. Moreover, we study the problem where each\nuser only reports once. Thus without loss of generality,\nwe ignore the instantaneous randomized response step\nand consider only the permanent randomized response\nwhen trying to identify effective protocols.\nAggregation. Let Bj be the reported vector of the j-th\nuser. Ignoring the Instantaneous randomized response\nstep, to estimate the number of times i occurs, the aggre-\ngator computes:\n˜c(i) =∑j 1 {i|Bj[i]=1}(i)− 1\n2 f n\n1 − f\nThat is, the aggregator first counts how many timei is re-\nported by computing ∑j 1 {i|Bj[i]=1}(i), which counts how\nmany reported vectors have the i’th bit being 1, and then\ncorrects for the effect of randomization. We use 1 X (i) to\ndenote the indicator function such that:\n1 X (i) =\n{\n1, if i ∈ X,\n0, if i /∈ X.\nCost. The communication and computing cost is Θ(d)\nfor each user, and Θ(nd) for the aggregator.\nPrivacy. Against an adversary who may observe\nmultiple transmissions, this achieves ε-LDP for ε =\nln\n((\n1−1\n2 f\n1\n2 f\n)2)\n, which is ln9 for f = 1/2 and ln49 for\nf = 1/4.\n2.3 RAPPOR\nBasic RAPPOR uses unary encoding, and does not scale\nwhen d is large. To address this problem, RAPPOR uses\nBloom filters [7]. While Bloom filters are typically used\nUSENIX Association 26th USENIX Security Symposium    731"
    },
    {
      "page_number": 5,
      "text": "to encode a set for membership testing, in RAPPOR it is\nused to encode a single element.\nEncoding. Encoding uses a set of m hash functions\nH = {H1,H2,..., Hm}, each of which outputs an integer\nin [k] ={0,1,..., k −1}. Encode(v) =B0, which is k-bit\nbinary vector such that\nB0[i] =\n{\n1, if ∃H ∈ H,s.t.,H(v) =i,\n0, otherwise.\nPerturbation. The perturbation process is identical to\nthat of Basic RAPPOR.\nAggregation. The use of shared hashing creates chal-\nlenges due to potential collisions. If two values happen\nto be hashed to the same set of indices, it becomes im-\npossible to distinguish them. To deal with this problem,\nRAPPOR introduces the concept of cohorts. The users\nare divided into a number of cohorts. Each cohort uses a\ndifferent set of hash functions, so that the effect of col-\nlisions is limited to within one cohort. However, par-\ntial collisions, i.e., two values are hashed to overlapping\n(though not identical) sets of indices, can still occur and\ninterfere with estimation. These complexities make the\naggregation algorithm more complicated. RAPPOR uses\nLASSO and linear regression to estimate frequencies of\nvalues.\nCost. The communication and computing cost is Θ(k)\nfor each user. The aggregator’s computation cost is\nhigher than Basic RAPPOR due to the usage of LASSO\nand regression.\nPrivacy. RAPPOR achieves ε-LDP for ε =\nln\n((\n1−1\n2 f\n1\n2 f\n)2m)\n. The RAPPOR implementation\nuses m = 2; thus this is ln81 ≈ 4.39 for f = 1/2 and\nln74 ≈ 7.78 for f = 1/4.\n2.4 Random Matrix Projection\nBassily and Smith [6] proposed a protocol that uses ran-\ndom matrix projection. This protocol has an additional\nSetup step.\nSetup. The aggregator generates a public matrix Φ ∈\n{− 1√m , 1√m }m×d uniformly at random. Here m is a pa-\nrameter determined by the error bound, where the “error”\nis defined as the maximal distance between the estima-\ntion and true frequency of any domain.\nEncoding. Encode(v) =⟨r,x⟩, where r is selected uni-\nformly at random from [m], and x is the v’s element of\nthe r’s row of Φ, i.e., x = Φ[r,v].\nPerturbation. Perturb(⟨r,x⟩) =⟨r, b ·c ·m ·x⟩, where\nb =\n{\n1 with probability p = eε\neε +1 ,\n−1 with probability q = 1\neε +1 ,\nc = (eε +1)/(eε −1).\nAggregation. Given reports ⟨r j,yj⟩’s, the estimate for\ni ∈ [d] is given by\n˜c(i) =∑\nj\nyj ·Φ[r j,i].\nThe effect is that each user with input value i contributes\nc to ˜c(i) with probability p, and −c with probability q;\nthus the expected contribution is\n(p −q)·c =\n( eε\neε +1 − 1\neε +1\n)\n· eε +1\neε −1 = 1.\nBecause of the randomness inΦ, each user with value̸= i\ncontributes to ˜c(i) either c or −c, each with probability\n1/2; thus the expected contribution from all such users\nis 0. Note that each row in the matrix is essentially a\nrandom hashing function mapping each value in [d] to a\nsingle bit. Each user selects such a hash function, uses it\nto hash her value into one bit, and then perturbs this bit\nusing random response.\nCost. A straightforward implementation of the protocol\nis expensive. However, the public random matrixΦ does\nnot need to be explicitly computed. For example, using\na common pseudo-random number generator, each user\ncan randomly choose a seed to generate a row in the ma-\ntrix and send the seed in her report. With this technique,\nthe communication cost is Θ(logm) for each user, and\nthe computation cost is O(d) for computing one row of\nthe Φ. The aggregator needs Θ(dm) to generate Φ, and\nΘ(md) to compute the estimations.\n3 A Framework for LDP Protocols\nMultiple protocols have been proposed for estimating\nfrequencies under LDP, and one can envision other pro-\ntocols. A natural research question is how do they com-\npare with each other? Under the same level of privacy,\nwhich protocol provides better accuracy in aggregation,\nwith lower cost? Can we come up with even better ones?\nTo answer these questions, we define a class of LDP pro-\ntocols that we call “pure”.\nFor a protocol to be pure, we require the specifica-\ntion of an additional function Support, which maps each\npossible output y to a set of input values that y “sup-\nports”. For example, in the basic RAPPOR protocol, an\noutput binary vector B is interpreted as supporting each\n732    26th USENIX Security Symposium USENIX Association"
    },
    {
      "page_number": 6,
      "text": "input whose corresponding bit is 1, i.e., Support(B) =\n{i | B[i] =1}.\nDefinition 3 (Pure LDP Protocols) A protocol given by\nPE and Support is pure if and only if there exist two prob-\nability values p∗ > q∗ such that for all v1,\nPr[PE(v1) ∈ {y | v1 ∈ Support(y)}] =p∗,\n∀v2̸=v1 Pr[PE(v2) ∈ {y | v1 ∈ Support(y)}] =q∗.\nA pure protocol is in some sense “pure and simple”. For\neach input v1, the set {y | v1 ∈ Support(y)} identifies all\noutputs y that “support” v1, and can be called the support\nset of v1. A pure protocol requires the probability that\nany value v1 is mapped to its own support set be the same\nfor all values. We use p∗ to denote this probability. In\norder to satisfy LDP, it must be possible for a valuev2 ̸=\nv1 to be mapped to v1’s support set. It is required that\nthis probability, which we use q∗ to denote, must be the\nsame for all pairs of v1 and v2. Intuitively, we want p∗ to\nbe as large as possible, and q∗ to be as small as possible.\nHowever, satisfying ε-LDP requires that p∗\nq∗ ≤ eε .\nBasic RAPPOR is pure with p∗ = 1 − f\n2 and q∗ = f\n2 .\nRAPPOR is not pure because there does not exist a suit-\nable q∗ due to collisions in mapping values to bit vec-\ntors. Assuming the use of two hash functions, if v1 is\nmapped to [1,1,0,0], v2 is mapped to [1,0,1,0], and v3 is\nmapped to [0,0,1,1], then because [1,1,0,0] differs from\n[1,0,1,0] by only two bits, and from [0,0,1,1] by four\nbits, the probability that v2 is mapped to v1’s support set\nis higher than that ofv3 being mapped to v1’s support set.\nFor a pure protocol, let yj denote the submitted value\nby user j, a simple aggregation technique to estimate the\nnumber of times that i occurs is as follows:\n˜c(i) =∑j 1 Support(yj)(i)−nq∗\np∗ −q∗ (1)\nThe intuition is that each output that supports i gives an\ncount of 1 for i. However, this needs to be normalized,\nbecause even if every input is i, we only expect to see\nn · p∗ outputs that support i, and even if input i never\noccurs, we expect to see n ·q∗ supports for it. Thus the\noriginal range of 0 to n is “compressed” into an expected\nrange of nq∗ to np∗. The linear transformation in (1)\ncorrects this effect.\nTheorem 1 For a pure LDP protocol PE and Support,\n(1) is unbiased, i.e., ∀iE[ ˜c(i)] =n fi, where fi is the frac-\ntion of times that the value i occurs.\nProof 1\nE[ ˜c(i)] =E\n⎡\n⎣\n(\n∑j 1 Support(yj)(i)\n)\n−nq∗\np∗ −q∗\n⎤\n⎦\n=n fi p∗ +n(1 − fi)q∗ −nq∗\np∗ −q∗\n=n · fi p∗ +q∗ − fiq∗ −q∗\np∗ −q∗\n=n fi\nThe variance of the estimator in 1 is a valuable indi-\ncator of an LDP protocol’s accuracy:\nTheorem 2 For a pure LDP protocol PE and Support,\nthe variance of the estimation ˜c(i) in (1) is:\nVar[˜c(i)] =nq∗(1 −q∗)\n(p∗ −q∗)2 + n fi(1 − p∗ −q∗)\np∗ −q∗ (2)\nProof 2 The random variable ˜c(i) is the (scaled) sum-\nmation of n independent random variables drawn from\nthe Bernoulli distribution. More specifically, n f i (resp.\n(1 − fi)n) of these random variables are drawn from\nthe Bernoulli distribution with parameter p ∗ (resp. q ∗).\nThus,\nVar[˜c(i)] =Var\n⎡\n⎣\n(\n∑j 1 Support(yj)(i)\n)\n−nq∗\np∗ −q∗\n⎤\n⎦\n= ∑j Var[1 Support(yj)(i)]\n(p∗ −q∗)2\n= n fi p∗(1 − p∗)+ n(1 − fi)q∗(1 −q∗)\n(p∗ −q∗)2\n= nq∗(1 −q∗)\n(p∗ −q∗)2 + n fi(1 − p∗ −q∗)\np∗ −q∗ (3)\nIn many application domains, the vast majority of val-\nues appear very infrequently, and one wants to identify\nthe more frequent ones. The key to avoid having lots of\nfalse positives is to have low estimation variances for the\ninfrequent values. When fi is small, the variance in (2) is\ndominated by the first term. We use Var ∗ to denote this\napproximation of the variance, that is:\nVar∗[˜c(i)] =nq∗(1 −q∗)\n(p∗ −q∗)2 (4)\nWe also note that some protocols have the property that\np∗ +q∗ = 1, in which case Var∗ = Var.\nAs the estimation ˜c(i) is the sum of many independent\nrandom variables, its distribution is very close to a nor-\nmal distribution. Thus, the mean and variance of ˜ c(i)\nfully characterizes the distribution of ˜ c(i) for all prac-\ntical purposes. When comparing different methods, we\nobserve that fixing ε, the differences are reflected in the\nconstants for the variance, which is where we focus our\nattention.\nUSENIX Association 26th USENIX Security Symposium    733"
    },
    {
      "page_number": 7,
      "text": "4 Optimizing LDP Protocols\nWe now cast many protocols that have been proposed\ninto our framework of “pure” LDP protocols. Casting\nthese protocols into the framework of pure protocols en-\nables us to derive their variances and understand how\neach method’s accuracy is affected by parameters such\nas domain size, ε, etc. This also enables us to general-\nize and optimize these protocols and propose two new\nprotocols that improve upon existing ones. More specifi-\ncally, we will consider the following protocols, which we\norganize by their encoding methods.\n• Direct Encoding (DE).There is no encoding. It is a\ngeneralization of the Random Response technique.\n• Histogram Encoding (HE). An input v is encoded\nas a histogram for thed possible values. The pertur-\nbation step adds noise from the Laplace distribution\nto each number in the histogram. We consider two\naggregation techniques, SHE and THE.\n– Summation with Histogram Encoding\n(SHE) simply sums up the reported noisy\nhistograms from all users.\n– Thresholding with Histogram Encoding\n(THE) is parameterized by a value θ; it inter-\nprets each noisy count above a threshold θ as\na 1, and each count below θ as a 0.\n• Unary Encoding (UE). An input v is encoded as a\nlength-d bit vector, with only the bit corresponding\nto v set to 1. Here two key parameters in perturba-\ntion are p, the probability that 1 remains 1 after per-\nturbation, and q, the probability that 0 is perturbed\ninto 1. Depending on their choices, we have two\nprotocols, SUE and OUE.\n– Symmetric Unary Encoding ( SUE) uses p +\nq = 1; this is the Basic RAPPOR proto-\ncol [13].\n– Optimized Unary Encoding ( OUE) uses op-\ntimized choices of p and q; this is newly pro-\nposed in this paper.\n• Local Hashing (LH). An input v is encoded by\nchoosing at random H from a universal hash func-\ntion family H, and then outputting (H,H(v)). This\nis called Local Hashing because each user chooses\nindependently the hash function to use. Here a key\nparameter is the range of these hash functions. De-\npending on this range, we have two protocols, BLH\nand OLH.\n– Binary Local Hashing (BLH) uses hash func-\ntions that outputs a single bit. This is equiva-\nlent to the random matrix projection technique\nin [6].\n– Optimized Local Hashing ( OLH) uses opti-\nmized choices for the range of hash functions;\nthis is newly proposed in this paper.\n4.1 Direct Encoding (DE)\nOne natural method is to extend the binary response\nmethod to the case where the number of input values is\nmore than 2. This is used in [23].\nEncoding and Perturbing. EncodeDE(v) = v, and\nPerturb is defined as follows.\nPr[PerturbDE(x) =i] =\n{\np = eε\neε +d−1 , if i = x\nq = 1−p\nd−1 = 1\neε +d−1 , if i ̸= x\nTheorem 3 (Privacy of DE) The Direct Encoding (DE)\nProtocol satisfies ε-LDP .\nProof 3 For any inputs v1,v2 and output y, we have:\nPr[PEDE(v1) =y]\nPr[PEDE(v2) =y] ≤ p\nq = eε /(eε +d −1)\n1/(eε +d −1) = eε\nAggregation. Let the Support function for DE be\nSupportDE(i) ={i}, i.e., each output value i supports\nthe input i. Then this protocol is pure, with p∗ = p and\nq∗ = q. Plugging these values into (4), we have\nVar∗[˜cDE(i)] =n · d −2 +eε\n(eε −1)2\nNote that the variance given above is linear in nd. As d\nincreases, the accuracy of DE suffers. This is because,\nas d increases, p = eε\neε +d−1 , the probability that a value\nis transmitted correctly, becomes smaller. For example,\nwhen eε = 49 and d = 216, we have p = 49\n65584 ≈ 0.00075.\n4.2 Histogram Encoding (HE)\nIn Histogram Encoding (HE), an inputx ∈ [d] is encoded\nusing a length-d histogram.\nEncoding. EncodeHE(v) = [0.0,0.0,··· ,1.0,··· ,0.0],\nwhere only the v-th component is 1.0. Two different in-\nput v values will result in two vectors that have L1 dis-\ntance of 2.0.\nPerturbing. PerturbHE(B) outputs B′ such that B′[i] =\nB[i]+ Lap\n(2\nε\n)\n, where Lap(β) is the Laplace distribution\nwhere Pr[Lap(β) =x] = 1\n2β e−|x|/β .\nTheorem 4 (Privacy of HE) The Histogram Encoding\nprotocol satisfies ε-LDP .\nProof 4 For any inputs v1,v2, and output B, we have\nPr[B|v1]\nPr[B|v2] =\n∏i∈[d] Pr[B[i]|v1]\n∏i∈[d] Pr[B[i]|v2] = Pr[B[v1]|v1]Pr[B[v2]|v1]\nPr[B[v1]|v2]Pr[B[v2]|v2]\n≤ eε/2 ·eε/2 = eε\n734    26th USENIX Security Symposium USENIX Association"
    },
    {
      "page_number": 8,
      "text": "Aggregation: Summation with Histogram Encoding\n(SHE) works as follows: For each value, sum the noisy\ncounts for that value reported by all users. That is,\n˜cSHE(i) =∑j Bj[i], where Bj is the noisy histogram re-\nceived from user j. This aggregation method does not\nprovide a Support function and is not pure. We prove its\nproperty as follows.\nTheorem 5 In SHE, the estimation ˜cSHE is unbiased.\nFurthermore, the variance is\nVar[ ˜cSHE(i)] =n 8\nε2\nProof 5 Since the added noise is 0-mean; the expected\nvalue of the sum of all noisy counts is the true count.\nThe Lap(β) distribution has variance 2\nβ2 , since β = ε\n2\nfor each B j[i], then the variance of each such variable\nis 8\nε2 , and the sum of n such independent variables have\nvariance n 8\nε2 .\nAggregation: Thresholding with Histogram Encod-\ning (THE) interprets a vector of noisy counts discretely\nby defining\nSupportTHE(B) ={v | B[v] > θ}\nThat is, each noise count that is > θ supports the corre-\nsponding value. This thresholding step can be performed\neither by the user or by the aggregator. It does not ac-\ncess the original value, and thus does not affect the pri-\nvacy guarantee. Using thresholding to provide aSupport\nfunction makes the protocol pure. The probabilityp∗ and\nq∗ are given by\np∗ = 1 −F(θ −1); q∗ = 1 −F(θ),\nwhere F(x) =\n{ 1\n2 e\nε\n2 x, if x < 0\n1 − 1\n2 e−ε\n2 x, if x ≥ 0\nHere, F(·) is the cumulative distribution function of\nLaplace distribution. If 0 ≤ θ ≤ 1, then we have\np∗ = 1 − 1\n2e\nε\n2 (θ−1); q∗ = 1\n2e−ε\n2 θ .\nPlugging these values into (4), we have\nVar∗[˜cHET(i)] =n · 2eεθ /2 −1\n(1 +eε(θ−1/2) −2eεθ /2)2\nComparing SHE and THE. Fixing ε, one can choose\na θ value to minimize the variance. Numerical analy-\nsis shows that the optimal θ is in (1\n2 ,1), and depends on\nε. When ε is large, θ → 1. Furthermore, Var [˜cTHE] <\nVar[˜cSHE] is always true. This means that by thresh-\nolding, one improves upon directly summing up noisy\ncounts, likely because thresholding limits the impact of\nnoises of large magnitude. In Section 5, we illustrate the\ndifferences between them using actual numbers.\n4.3 Unary Encoding (UE)\nBasic RAPPOR, which we described in Section 2.2,\ntakes the approach of directly perturbing a bit vector. We\nnow explore this method further.\nEncoding. Encode(v) = [0,··· ,0,1,0,··· ,0], a length-d\nbinary vector where only the v-th position is 1.\nPerturbing. Perturb(B) outputs B′ as follows:\nPr\n[\nB′[i] =1\n]\n=\n{\np, if B[i] =1\nq, if B[i] =0\nTheorem 6 (Privacy of UE) The Unary Encoding pro-\ntocol satisfies ε-LDP for\nε = ln\n(p(1 −q)\n(1 − p)q\n)\n(5)\nProof 6 For any inputs v1,v2, and output B, we have\nPr[B|v1]\nPr[B|v2] =∏i∈[d] Pr[B[i]|v1]\n∏i∈[d] Pr[B[i]|v2] (6)\n≤Pr[B[v1] =1|v1]Pr[B[v2] =0|v1]\nPr[B[v1] =1|v2]Pr[B[v2] =0|v2] (7)\n= p\nq · 1 −q\n1 − p = eε\n(6) is because each bit is flipped independently, and(7) is\nbecause v1 and v2 result in bit vectors that differ only in\nlocations v1 and v2, and a vector with position v 1 being\n1 and position v2 being 0 maximizes the ratio.\nAggregation. A reported bit vector is viewed as support-\ning an input i if B[i] =1, i.e., SupportUE(B) ={i | B[i] =\n1}. This yields p∗ = p and q∗ = q. Interestingly, (5)\ndoes not fully determine the values of p and q for a fixed\nε. Plugging (5) into (4), we have\nVar∗[˜cUE(i)] =nq(1 −q)\n(p −q)2 = nq(1 −q)\n( eε q\n1−q+eε q −q)2\n= n · ((eε −1)q +1)2\n(eε −1)2(1 −q)q. (8)\nSymmetric UE ( SUE). RAPPOR’s implementation\nchooses p and q such that p + q = 1; making the treat-\nment of 1 and 0 symmetric. Combining this with (5), we\nhave\np = eε/2\neε/2 +1, q = 1\neε/2 +1\nPlugging these into (8), we have\nVar∗[˜cSUE(i)] =n · eε/2\n(eε/2 −1)2\nUSENIX Association 26th USENIX Security Symposium    735"
    },
    {
      "page_number": 9,
      "text": "Optimized UE (OUE). Instead of making p and q sym-\nmetric, we can choose them to minimize (8). Take the\npartial derivative of (8) with respect to q, and solving q\nto make the result 0, we get:\n∂\n[ ((eε −1)q+1)2\n(eε −1)2(1−q)q\n]\n∂q =\n∂\n[\n1\n(eε −1)2 ·\n((eε −1)2q\n1−q + 2(eε −1)\n1−q + 1\nq(1−q)\n)]\n∂q\n=\n∂\n[\n1\n(eε −1)2 ·\n(\n−(eε −1)2 + e2ε\n1−q + 1\nq\n)]\n∂q\n= 1\n(eε −1)2\n( e2ε\n(1 −q)2 − 1\nq2\n)\n= 0\n=⇒ 1 −q\nq = eε ,i.e.,q = 1\neε +1 and p = 1\n2\nPlugging p = 1\n2 and q = 1\neε +1 into (8), we get\nVar∗[˜cOUE(i)] =n 4eε\n(eε −1)2 (9)\nThe reason why setting p = 1\n2 and q = 1\neε +1 is opti-\nmal when the true frequencies are small may be unclear\nat first glance; however, there is an intuition behind it.\nWhen the true frequencies are small, d is large. Recall\nthat eε = p\n1−p\n1−q\nq . Setting p and q can be viewed as\nsplitting ε into ε1 +ε2 such that p\n1−p = eε1 and 1−q\nq = eε2 .\nThat is, ε1 is the privacy budget for transmitting the 1 bit,\nand ε2 is the privacy budget for transmitting each 0 bit.\nSince there are many 0 bits and a single 1 bit, it is better\nto allocate as much privacy budget for transmitting the 0\nbits as possible. In the extreme, settingε1 = 0 and ε2 = ε\nmeans that setting p = 1\n2 .\n4.4 Binary Local Hashing (BLH)\nBoth HE and UE use unary encoding and have Θ(d)\ncommunication cost, which is too large for some appli-\ncations. To reduce the communication cost, a natural\nidea is to first hash the input value into a domain of size\nk < d, and then apply the UE method to the hashed value.\nThis is the basic idea underlying the RAPPOR method.\nHowever, a problem with this approach is that two val-\nues may be hashed to the same output, making them in-\ndistinguishable from each other during decoding. RAP-\nPOR tries to address this in several ways. One is to use\nmore than one hash functions; this reduces the chance of\na collision. The other is to use cohorts, so that differ-\nent cohorts use different sets of hash functions. These\nremedies, however, do not fully eliminate the potential\neffect of collisions. Using more than one hash functions\nalso means that every individual bit needs to be perturbed\nmore to satisfy ε-LDP for the same ε.\nA better approach is to make each user belong to a co-\nhort by herself. We call this the local hashing approach.\nThe random matrix-base protocol in [6] (described in\nSection 2.4), in its very essence, uses a local hashing en-\ncoding that maps an input value to a single bit, which is\nthen transmitted using randomized response. Below is\nthe Binary Local Hashing (BLH) protocol, which is log-\nically equivalent to the one in Section 2.4, but is simpler\nand, we hope, better illustrates the essence of the idea.\nLet H be a universal hash function family, such that\neach hash function H ∈ H hashes an input in [d] into one\nbit. The universal property requires that\n∀x,y ∈ [d],x ̸= y : Pr\nH∈H\n[H(x) =H(y)] ≤ 1\n2.\nEncoding. EncodeBLH(v) =⟨H,b⟩, where H ←R H is\nchosen uniformly at random fromH, and b = H(v). Note\nthat the hash function H can be encoded using an index\nfor the family H and takes only O(logn) bits.\nPerturbing. PerturbBLH(⟨H,b⟩) =⟨H,b′⟩ such that\nPr\n[\nb′ = 1\n]\n=\n{\np = eε\neε +1 , if b = 1\nq = 1\neε +1 , if b = 0\nAggregation. SupportBLH(⟨H,b⟩) ={v | H(v) =b},\nthat is, each reported ⟨H,b⟩ supports all values that are\nhashed by H to b, which are half of the input values. Us-\ning this Support function makes the protocol pure, with\np∗ = p and q∗ = 1\n2 p+ 1\n2 q = 1\n2 . Plugging the values of p∗\nand q∗ into (4), we have\nVar∗[˜cBLH(i)] =n · (eε +1)2\n(eε −1)2 .\n4.5 Optimal Local Hashing (OLH)\nOnce the random matrix projection protocol is cast as\nbinary local hashing, we can clearly see that the encoding\nstep loses information because the output is just one bit.\nEven if that bit is transmitted correctly, we can get only\none bit of information about the input, i.e., to which half\nof the input domain does the value belong. When ε is\nlarge, the amount of information loss in the encoding step\ndominates that of the random response step. Based on\nthis insight, we generalize Binary Local Hashing so that\neach input value is hashed into a value in [g], where g ≥\n2. A larger g value means that more information is being\npreserved in the encoding step. This is done, however, at\na cost of more information loss in the random response\nstep. As in our analysis of the Direct Encoding method,\na large domain results in more information loss.\nLet H be a universal hash function family such that\neach H ∈ H outputs a value in [g].\nEncoding. Encode(v) =⟨H,x⟩, where H ∈ H is chosen\n736    26th USENIX Security Symposium USENIX Association"
    },
    {
      "page_number": 10,
      "text": "uniformly at random, and x = H(v).\nPerturbing. Perturb(⟨H,x⟩) = (⟨H,y⟩), where\n∀i∈[g] Pr[y = i] =\n{\np = eε\neε +g−1 , if x = i\nq = 1\neε +g−1 , if x ̸= i\nTheorem 7 (Privacy of LH) The Local Hashing ( LH)\nProtocol satisfies ε-LDP\nProof 7 For any two possible input values v1,v2 and any\noutput ⟨H,y⟩, we have,\nPr[⟨H,y⟩|v1]\nPr[⟨H,y⟩|v2] = Pr[Perturb(H(v1)) =y]\nPr[Perturb(H(v2)) =y] ≤ p\nq = eε\nAggregation. Let SupportLH(⟨H,y⟩) ={i | H(i) =y},\ni.e., the set of values that are hashed into the reported\nvalue. This gives rise to a pure protocol with\np∗ = p and q∗ = 1\ng p + g −1\ng q = 1\ng.\nPlugging these values into (4), we have the\nVar∗[˜cLP(i)] =n · (eε −1 +g)2\n(eε −1)2(g −1). (10)\nOptimized LH (OLH) Now we find the optimal g\nvalue, by taking the partial derivative of (10) with respect\nto g.\n∂\n[\n(eε −1+g)2\n(eε −1)2(g−1)\n]\n∂g =\n∂\n[\ng−1\n(eε −1)2 + 1\ng−1 · e2ε\n(eε −1)2 + 2eε\n(eε −1)2\n]\n∂g\n= 1\n(eε −1)2 − 1\n(g −1)2 · e2ε\n(eε −1)2 = 0\n=⇒ g = eε +1\nWhen g = eε + 1, we have p∗ = eε\neε +g−1 = 1\n2 , q∗ = 1\ng =\n1\neε +1 into (8), and\nVar∗[˜cOLH(i)] =n · 4eε\n(eε −1)2 . (11)\nComparing OLH with OUE. It is interesting to observe\nthat the variance we derived for optimized local hashing\n(OLH), i.e., (11) is exactly that we have for optimized\nunary encoding (OUE), i.e., (9). Furthermore, the proba-\nbility values p∗ and q∗ are also exactly the same. This il-\nlustrates that OLH and OUE are in fact deeply connected.\nOLH can be viewed as a compact way of implementing\nOUE. Compared with OUE, OLH has communication\ncost O(logn) instead of O(d).\nThe fact that optimizing two apparently different en-\ncoding approaches, namely, unary encoding and lo-\ncal hashing, results in conceptually equivalent protocol,\nseems to suggest that this may be optimal (at least when\nd is large). However, whether this is the best possible\nprotocol remains an interesting open question.\n5 Which Protocol to Use\nWe have cast most of the LDP protocols proposed in the\nliterature into our framework of pure LDP protocols. Do-\ning so also enables us to generalize and optimize exist-\ning protocols. Now we are able to answer the question:\nWhich LDP protocol should one use in a given setting?\nGuideline. Table 1 lists the major parameters for the dif-\nferent protocols. Histogram encoding and unary encod-\ning requires Θ(d) communication cost, and is expensive\nwhen d is large. Direct encoding and local hashing re-\nquire Θ(logd) or Θ(logn) communication cost, which\namounts to a constant in practice. All protocols other\nthan DE have O(n ·d) computation cost to estimate fre-\nquency of all values.\nNumerical values of the approximate variances using\n(4) for all protocols are given in Table 2 and Figure 1 (n =\n10,000). Our analysis gives the following guidelines for\nchoosing protocols.\n• When d is small, more precisely, whend < 3eε +2,\nDE is the best among all approaches.\n• When d > 3eε + 2, and the communication cost\nΘ(d) is acceptable, one should use OUE. (OUE has\nthe same variance as OLH, but is easier to imple-\nment and faster because no hash functions is used.)\n• When d is so large that the communication cost\nΘ(d) is too large, we should use OLH. It offers\nthe same accuracy as OUE, but has communication\ncost O(logd) instead of O(d).\nDiscussion. In addition to the guidelines, we make the\nfollowing observations. Adding Laplacian noises to a\nhistogram is typically used in a setting with a trusted\ndata curator, who first computes the histogram from all\nusers’ data and then adds the noise. SHE applies it to\neach user’s data. Intuitively, this should perform poorly\nrelative to other protocols specifically designed for the\nlocal setting. However, SHE performs very similarly to\nBLH, which was specifically designed for the local set-\nting. In fact, when ε > 2.5, SHE performs better than\nBLH.\nWhile all protocols’ variances depend on ε, the rela-\ntionships are different. BLH is least sensitive to change\nin ε because binary hashing loses too much information.\nIndeed, while all other protocols have variance goes to\n0 when ε goes to infinity, BLH has variance goes to n.\nSHE is slightly more sensitive to change in ε. DE is\nmost sensitive to change in ε; however, when d is large,\nits variance is very high. OLH and OUE are able to better\nbenefit from an increase in ε, without suffering the poor\nperformance for small ε values.\nAnother interesting finding is that when d = 2, the\nvariance of DE is eε\n(eε −1)2 , which is exactly 1\n4 of that of\nUSENIX Association 26th USENIX Security Symposium    737"
    },
    {
      "page_number": 11,
      "text": "DE SHE THE (θ = 1) SUE OUE BLH OLH\nCommunication Cost O(logd) O(d) O(d) O(d) O(d) O(logn) O(logn)\nVar[˜c(i)]/n d−2+eε\n(eε −1)2\n8\nε2\n2eε/2−1\n(eε/2−1)2\neε/2\n(eε/2−1)2\n4eε\n(eε −1)2\n(eε +1)2\n(eε −1)2\n4eε\n(eε −1)2\nTable 1: Comparison of communication cost and variances for different methods.\nDE (d = 2) DE (d = 32) DE (d = 210) SHE THE (θ = 1) SUE OUE BLH OLH\nε = 0.5 3.92 75.20 2432.40 32.00 19.44 15.92 15.67 16.67 15.67\nε = 1.0 0.92 11.08 347.07 8.00 5.46 3.92 3.68 4.68 3.68\nε = 2.0 0.18 0.92 25.22 2.00 1.50 0.92 0.72 1.72 0.72\nε = 4.0 0.02 0.03 0.37 0.50 0.34 0.18 0.08 1.08 0.08\nTable 2: Numerical values of Var [˜c(i)]/n for different methods.\n102\n103\n104\n105\n106\n107\n 0.5  1  1.5  2  2.5  3  3.5  4  4.5  5\nVar\nε\nDE(d=2)\nDE(d=4)\nDE(d=16)\nDE(d=128)\nDE(d=2048)\nOUE\n(a) Vary ε\n102\n103\n104\n105\n106\n107\n 0.5  1  1.5  2  2.5  3  3.5  4  4.5  5\nVar\nε\nDE\nSHE\nSUE\nOUE\nBLH\nOLH (b) Vary ε (fixing d = 210)\nFigure 1: Numerical values of Var[˜c(i)] for different methods.\nOUE and OLH, whose variances do not depend ond. In-\ntuitively, it is easier to transmit a piece of information\nwhen it is binary, i.e., d = 2. As d increases, one needs\nto “pay” for this increase in source entropy by having\nhigher variance. However, it seems that there is a cap on\nthe “price” one must pay no matter how large d is, i.e.,\nOLH’s variance does not depend on d and is always 4\ntimes that of DE with d = 2. There may exist a deeper\nreason for this rooted in information theory. Exploring\nthese questions is beyond the scope of this paper.\n6 Experimental Evaluation\nWe empirically evaluate these protocols on both syn-\nthetic and real-world datasets. All experiments are per-\nformed ten times and we plot the mean and standard de-\nviation.\n6.1 Verifying Correctness of Analysis\nThe conclusions we drew above are based on analyti-\ncal variances. We now show that our analytical results\nof variances match the empirically measured squared er-\nrors. For the empirical data, we issue queries using the\nprotocols and measure the average of the squared errors,\nnamely, 1\nd ∑i∈[d] [˜c(i)−n fi]2, where fi is the fraction of\nusers taking value i. We run queries for all i values and\nrepeat for ten times. We then plot the average and stan-\ndard deviation of the squared error. We use synthetic data\ngenerated by following the Zipf’s distribution (with dis-\ntribution parameter s = 1.1 and n = 10,000 users), simi-\nlar to experiments in [13].\nFigure 2 gives the empirical and analytical results for\nall methods. In Figures 2(a) and 2(b), we fix ε = 4\nand vary the domain size. For sufficiently large d (e.g.,\nd ≥ 26), the empirical results match very well with the\nanalytical results. When d < 26, the analytical variance\ntends to underestimate the variance, because in (4) we\nignore the fi terms. Standard deviation of the measured\nsquared error from different runs also decreases when the\ndomain size increases. In Figures 2(c) and 2(d), we fix\nthe domain size to d = 210 and vary the privacy budget.\nWe can see that the analytical results match the empirical\nresults for all ε values and all methods.\nIn practice, since the group size g of OLH can only be\n738    26th USENIX Security Symposium USENIX Association"
    },
    {
      "page_number": 12,
      "text": "102\n103\n104\n105\n22 24 26 28 210 212 214 216 218\nVar\nd\nEmpirical DE\nEmpirical SUE\nEmpirical OUE\nAnalytical DE\nAnalytical SUE\nAnalytical OUE\n(a) Vary d (fixing ε = 4)\n102\n103\n104\n105\n22 24 26 28 210 212 214 216 218\nVar\nd\nEmpirical SHE\nEmpirical BLH\nEmpirical OLH\nAnalytical SHE\nAnalytical BLH\nAnalytical OLH (b) Vary d (fixing ε = 4)\n102\n103\n104\n105\n106\n107\n 0.5  1  1.5  2  2.5  3  3.5  4  4.5  5\nVar\nε\nEmpirical DE\nEmpirical SUE\nEmpirical OUE\nAnalytical DE\nAnalytical SUE\nAnalytical OUE\n(c) Vary ε (fixing d = 210)\n102\n103\n104\n105\n106\n107\n 0.5  1  1.5  2  2.5  3  3.5  4  4.5  5\nVar\nε\nEmpirical SHE\nEmpirical BLH\nEmpirical OLH\nAnalytical SHE\nAnalytical BLH\nAnalytical OLH (d) Vary ε (fixing d = 210)\nFigure 2: Comparing empirical and analytical variance.\nintegers, we round g = eε +1 to the nearest integer.\n6.2 Towards Real-world Estimation\nWe run OLH, BLH, together with RAPPOR, on real\ndatasets. The goal is to understand how does each pro-\ntocol perform in real world scenarios and how to inter-\npret the result. Note that RAPPOR does not fall into\nthe pure framework of LDP protocols so we cannot use\nTheorem 2 to obtain the variance analytically. Instead,\nwe run experiments to examine its performance empiri-\ncally. Following the setting of Erlingsson et al. [13], we\nuse a 128-bit Bloom filter, 2 hash functions and 8/16 co-\nhorts in RAPPOR. In order to vary ε, we tweak the f\nvalue. The instantaneous randomization process is omit-\nted. We implement RAPPOR in Python. The regression\npart, which RAPPOR introduces to handle the collisions\nin the Bloom filter, is implemented using Scikit-learn li-\nbrary [4].\nDatasets. We use the Kosarak dataset [2], which con-\ntains the click stream of a Hungarian news website.\nThere are around 8 million click events for 41 ,270 dif-\nferent pages. The goal is to estimate the popularity of\neach page, assuming all events are reported.\n6.2.1 Accuracy on Frequent Values\nOne goal of estimating a distribution is to find out the fre-\nquent values and accurately estimate them. We run dif-\nferent methods to estimate the distribution of the Kosarak\ndataset. After the estimation, we issue queries for the\n30 most frequent values in the original dataset. We then\ncalculate the average squared error of the 30 estimations\nproduced by different methods. Figure 3 shows the re-\nsult. We try RAPPOR with both 8 cohorts (RAP(8)) and\n16 cohorts (RAP(16)). It can be seen that when ε > 1,\nOLH starts to show its advantage. Moreover, variance\nof OLH decreases fastest among the four. Due to the\ninternal collision caused by Bloom filters, the accuracy\nof RAPPOR does not benefit from larger ε. We also per-\nform this experiment on different datasets, and the results\nare similar.\n6.2.2 Distinguish True Counts from Noise\nAlthough there are noises, infrequent values are still un-\nlikely to be estimated to be frequent. Statistically, the fre-\nquent estimates are more reliable, because the probabil-\nity it is generated from an infrequent value is quite low.\nHowever, for the infrequent estimates, we don’t know\nwhether it comes from an originally infrequent value or\nUSENIX Association 26th USENIX Security Symposium    739"
    },
    {
      "page_number": 13,
      "text": "105\n106\n107\n108\n109\n1010\n 0.5  1  1.5  2  2.5  3  3.5  4  4.5  5\nVar\nε\nOLH\nBLH\nRAP(8)\nRAP(16)\nFigure 3: Average squared error, varying ε.\n 0\n 50\n 100\n 150\n 200\n 250\n 300\n 350\n 400\n 450\n 0.5  1  1.5  2  2.5  3  3.5  4  4.5  5\nTP\nε\nOLH\nBLH\nRAP(8)\nRAP(16)\nFigure 4: Number of true positives, varying ε, using\nsignificance threshold. The dashed line corresponds to\nthe average number of items identified.\na zero-count value. Therefore, after getting the estima-\ntion, we need to choose which estimate to use, and which\nto discard.\nSignificance Threshold. In [13], the authors propose\nto use the significance threshold. After the estimation,\nall estimations above the threshold are kept, and those\nbelow the threshold Ts are discarded.\nTs = Φ−1\n(\n1 − α\nd\n)√\nVar∗,\nwhere d is the domain size, Φ−1 is the inverse of the\ncumulative density function of standard normal distri-\nbution, and the term inside the square root is the vari-\nance of the protocol. Roughly speaking, the parame-\nter α controls the number of values that originally have\nlow frequencies but estimated to have frequencies above\nthe threshold (also known as false positives). We use\nα = 0.05 in our experiment.\nFor the values whose estimations are discarded, we\ndon’t know for sure whether they have low or zero fre-\nquencies. Thus, a common approach is to assign the re-\nmaining probability to each of them uniformly.\nRecall Var∗ is the term we are trying to minimize. So a\nprotocol with a smaller variance will have a lower thresh-\nold; thus more values can be detected reliably.\nNumber of Reliable Estimation. We run different pro-\ntocols using the significance threshold Ts on the Kosarak\ndataset. Note that Ts will change as ε changes. We define\na true (false) positive as a value that has frequency above\n(below) the threshold, and is estimated to have frequency\nabove the threshold. In Figure 4, we show the number of\ntrue positives versus ε. As ε increases, the number of\ntrue positives increases. When ε = 4, RAPPOR can out-\nput 75 true positives, BLH can only output 36 true posi-\ntives, but OLH can output nearly 200 true positives. We\nalso notice that the output sizes are similar for RAPPOR\nand OLH, which indicates that OLH gives out very few\nfalse positives compared to RAPPOR. The cohort size\ndoes not affect much in this setting.\n6.2.3 On Information Quality\nNow we test both the number of true positives and false\npositives, varying the threshold. We run OLH, BLH and\nRAPPOR on the Kosarak dataset.\nAs we can see in Figure 5(a), fixing a threshold, OLH\nand BLH performs similarly in identifying true positives,\nwhich is as expected, because frequent values are rare,\nand variance does not change much the probability it is\nidentified. RAPPOR performs slightly worse because of\nthe Bloom filter collision.\nAs for the false positives, as shown in Figure 5(b), dif-\nferent protocols perform quite differently in eliminating\nfalse positives. When fixing Ts to be 5 ,000, OLH pro-\nduces tens of false positives, but BLH will produce thou-\nsands of false positives. The reason behind this is that,\nfor the majority of infrequent values, their estimations\nare directly related to the variance of the protocol. A\nprotocol with a high variance means that more infrequent\nvalues will become frequent during estimation. As a re-\nsult, because of its smallest Var∗, OLH produces the least\nfalse positives while generating the most true positives.\n7 Related Work\nThe notion of differential privacy and the technique of\nadding noises sampled from the Laplace distribution\nwere introduced in [11]. Many algorithms for the central-\nized setting have been proposed. See [12] for a theoreti-\ncal treatment of these techniques, and [19] for a treatment\nfrom a more practical perspective. It appears that only\nalgorithms for the LDP settings have seen real world de-\nployment. Google deployed RAPPOR [13] in Chrome,\nand Apple [1] also uses similar methods to help with pre-\ndictions of spelling and other things.\nState of the art protocols for frequency estimation un-\nder LDP are RAPPOR by Erlingsson et al. [13] and Ran-\ndom Matrix Projection (BLH) by Bassily and Smith [6],\n740    26th USENIX Security Symposium USENIX Association"
    },
    {
      "page_number": 14,
      "text": " 0\n 20\n 40\n 60\n 80\n 100\n 120\n 140\n 160\n 5000  10000  15000  20000\nTP\nThreshold\nOLH\nBLH\nRAP(8)\nRAP(16)\n(a) Number of True Positives\n100\n101\n102\n103\n104\n 5000  10000  15000  20000\nFP\nThreshold\nOLH\nBLH\nRAP(8)\nRAP(16) (b) Number of False Positives\nFigure 5: Results on Kosarak dataset. The y axes are the number of identified hash values that is true/false positive.\nThe x axes are the threshold. We assume ε = 4.\nwhich we have presented in Section 2 and compared with\nin detail in the paper. These protocols use ideas from\nearlier work [20, 9]. Our proposed Optimized Unary\nEncoding (OUE) protocol builds upon the Basic RAP-\nPOR protocol in [13]; and our proposed Optimized Lo-\ncal Hashing (OLH) protocol is inspired by BLH in [6].\nWang et al. [23] uses both generalized random response\n(Section 4.1) and Basic RAPPOR for learning weighted\nhistogram. Some researchers use existing frequency esti-\nmation protocols as primitives to solve other problems in\nLDP setting. For example, Chen et al. [8] uses BLH [6]\nto learn location information about users. Qin et al. [22]\nuse RAPPOR [13] and BLH [6] to estimate frequent\nitems where each user has a set of items to report. These\ncan benefit from the introduction of OUE and OLH in\nthis paper.\nThere are other interesting problems in the LDP set-\nting beyond frequency estimation. In this paper we do\nnot study them. One problem is to identify frequent val-\nues when the domain of possible input values is very\nlarge or even unbounded, so that one cannot simply ob-\ntain estimations for all values to identify which ones are\nfrequent. This problem is studied in [17, 6, 16]. Another\nproblem is estimating frequencies of itemsets [14, 15].\nNguyˆen et al. [21] studied how to report numerical an-\nswers (e.g., time of usage, battery volume) under LDP.\nWhen these protocols use frequency estimation as a\nbuilding block (such as in [16]), they can directly ben-\nefit from results in this paper. Applying insights gained\nin our paper to better solve these problems is interesting\nfuture work.\nKairouz et al. [18] study the problem of finding the\noptimal LDP protocol for two goals: (1) hypothesis test-\ning, i.e., telling whether the users’ inputs are drawn from\ndistribution P0 or P1, and (2) maximize mutual informa-\ntion between input and output. We note that these goals\nare different from ours. Hypothesis testing does not re-\nflect dependency on d. Mutual information considers\nonly a single user’s encoding, and not aggregation ac-\ncuracy. For example, both global and local hashing have\nexactly the same mutual information characteristics, but\nthey have very different accuracy for frequency estima-\ntion, because of collisions in global hashing. Neverthe-\nless, it is found that for very large ε’s, Direct Encoding\nis optimal, and for very small ε’s, BLH is optimal. This\nis consistent with our findings. However, analysis in [18]\ndid not lead to generalization and optimization of binary\nlocal hashing, nor does it provide concrete suggestion on\nwhich method to use for a given ε and d value.\n8 Discussion\nOn answering multiple questions. In the setting of tra-\nditional DP, the privacy budget is split when answering\nmultiple queries. In the local setting, previous work fol-\nlow this tradition and let the users split privacy budget\nevenly and report on multiple questions. Instead, we sug-\ngest partitioning the users randomly into groups, and let-\nting each group of users answer a separate question. Now\nwe compare the utilities by these approaches.\nSuppose there are Q ≥ 2 questions. We calculate vari-\nances on one question. Since there are different number\nof users in the two cases ( n versus n/Q), we normalize\nthe estimations into the range from 0 to 1. In OLH, the\nvariance is σ2 = Var∗[˜cOLH(i)/n] = 4eε\n(eε −1)2·n .\nWhen partitioning the users, n/Q users answer one\nquestion, rendering σ2\n1 = 4Qeε\n(eε −1)2·n ; when privacy bud-\nget is split, ε/Q is used for one question, we have σ2\n2 =\n4eε/Q\n(eε/Q−1)\n2·n\n. We want to show σ2\n1 < σ2\n2 :\nσ2\n2 −σ2\n1\nUSENIX Association 26th USENIX Security Symposium    741"
    },
    {
      "page_number": 15,
      "text": "=4\nn\n(\neε/Q\n(\neε/Q −1\n)2 − Qeε\n(eε −1)2\n)\n= 4eε/Q\nn\n(\neε/Q −1\n)2 (eε −1)2\n·\n[\n(eε −1)2 −Qeε−ε/Q\n(\neε/Q −1\n)2]\nThe first term is always greater than zero sinceε > 0. For\nthe second term, we define eε/Q = z, and write it as:\n(zQ −1)2 −QzQ−1(z −1)2\n=(z −1)2 ·\n[\n(zQ−1 +zQ−2 +... +1)2 −QzQ−1]\n> 0\nTherefore, σ2\n1 is always smaller than σ2\n2 . Thus utility\nof partitioning users is better than splitting privacy bud-\nget.\nLimitations. The current work only considers the frame-\nwork of pure LDP protocols. It is not known whether a\nprotocol that is not pure will produce more accurate re-\nsult or not. Moreover, current protocols can only handle\nthe case where the domain is limited, or a dictionary is\navailable. Other techniques are needed when the domain\nsize is very big.\n9 Conclusion\nIn this paper, we study frequency estimation in the Local\nDifferential Privacy (LDP) setting. We have introduced a\nframework of pure LDP protocols together with a simple\nand generic aggregation and decoding technique. This\nframework enables us to analyze, compare, generalize,\nand optimize different protocols, significantly improving\nour understanding of LDP protocols. More concretely,\nwe have introduced the Optimized Local Hashing (OLH)\nprotocol, which has much better accuracy than previous\nfrequency estimation protocols satisfying LDP. We pro-\nvide a guideline as to which protocol to choose in differ-\nent scenarios. Finally we demonstrate the advantage of\nthe OLH in both synthetic and real-world datasets.\n10 Acknowledgment\nThis paper is based on work supported by the United\nStates National Science Foundation under Grant No.\n1640374.\nReferences\n[1] Apples differential privacy is about col-\nlecting your databut not your data.\nhttps://www.wired.com/2016/06/\napples-differential-privacy-collecting-data/ .\n[2] Kosarak. http://fimi.ua.ac.be/data/.\n[3] Rappor online description. http:\n//www.chromium.org/developers/\ndesign-documents/rappor.\n[4] Scikit-learn. http://scikit-learn.org/.\n[5] Source code of rappor in chromium. https://cs.\nchromium.org/chromium/src/components/\nrappor/public/rappor_parameters.h.\n[6] B ASSILY, R., AND SMITH , A. Local, private, ef-\nficient protocols for succinct histograms. In Pro-\nceedings of the Forty-Seventh Annual ACM on Sym-\nposium on Theory of Computing (2015), ACM,\npp. 127–135.\n[7] B LOOM , B. H. Space/time trade-offs in hash cod-\ning with allowable errors. Commun. ACM 13 , 7\n(July 1970), 422–426.\n[8] C HEN , R., L I, H., Q IN, A. K., K A-\nSIVISWANATHAN , S. P., AND JIN, H. Private\nspatial data aggregation in the local setting. In\n32nd IEEE International Conference on Data\nEngineering, ICDE 2016, Helsinki, Finland, May\n16-20, 2016 (2016), pp. 289–300.\n[9] D UCHI , J. C., J ORDAN , M. I., AND WAIN -\nWRIGHT , M. J. Local privacy and statistical mini-\nmax rates. In FOCS (2013), pp. 429–438.\n[10] D WORK , C. Differential privacy. In ICALP (2006),\npp. 1–12.\n[11] D WORK , C., M CSHERRY, F., N ISSIM , K., AND\nSMITH , A. Calibrating noise to sensitivity in pri-\nvate data analysis. In TCC (2006), pp. 265–284.\n[12] D WORK , C., AND ROTH , A. The algorithmic\nfoundations of differential privacy. Foundations\nand Trends in Theoretical Computer Science 9 , 34\n(2014), 211–407.\n[13] E RLINGSSON , ´U., P IHUR , V., AND KOROLOVA ,\nA. Rappor: Randomized aggregatable privacy-\npreserving ordinal response. In Proceedings of the\n2014 ACM SIGSAC conference on computer and\ncommunications security (2014), ACM, pp. 1054–\n1067.\n[14] E VFIMIEVSKI , A., G EHRKE , J., AND SRIKANT ,\nR. Limiting privacy breaches in privacy preserving\ndata mining. In PODS (2003), pp. 211–222.\n[15] E VFIMIEVSKI , A., S RIKANT , R., A GRAWAL , R.,\nAND GEHRKE , J. Privacy preserving mining of as-\nsociation rules. In KDD (2002), pp. 217–228.\n742    26th USENIX Security Symposium USENIX Association"
    },
    {
      "page_number": 16,
      "text": "[16] F ANTI , G., P IHUR , V., AND ERLINGSSON , ´U.\nBuilding a rappor with the unknown: Privacy-\npreserving learning of associations and data dictio-\nnaries. Proceedings on Privacy Enhancing Tech-\nnologies (PoPETS) issue 3, 2016 (2016).\n[17] H SU, J., K HANNA , S., AND ROTH , A. Dis-\ntributed private heavy hitters. In International Col-\nloquium on Automata, Languages, and Program-\nming (2012), Springer, pp. 461–472.\n[18] K AIROUZ , P., O H, S., AND VISWANATH , P. Ex-\ntremal mechanisms for local differential privacy. In\nAdvances in neural information processing systems\n(2014), pp. 2879–2887.\n[19] L I, N., L YU, M., S U, D., AND YANG , W. Differ-\nential Privacy: From Theory to Practice . Synthe-\nsis Lectures on Information Security, Privacy, and\nTrust. Morgan Claypool, 2016.\n[20] M ISHRA , N., AND SANDLER , M. Privacy via\npseudorandom sketches. In Proceedings of the\ntwenty-fifth ACM SIGMOD-SIGACT-SIGART sym-\nposium on Principles of database systems (2006),\nACM, pp. 143–152.\n[21] N GUY ˆEN, T. T., XIAO , X., YANG , Y., HUI, S. C.,\nSHIN , H., AND SHIN , J. Collecting and analyzing\ndata from smart device users with local differential\nprivacy. arXiv preprint arXiv:1606.05053 (2016).\n[22] Q IN, Z., Y ANG , Y., Y U, T., K HALIL , I., X IAO ,\nX., AND REN, K. Heavy hitter estimation over set-\nvalued data with local differential privacy. In CCS\n(2016).\n[23] W ANG , S., H UANG , L., W ANG , P., D ENG , H.,\nXU, H., AND YANG , W. Private weighted his-\ntogram aggregation in crowdsourcing. In Interna-\ntional Conference on Wireless Algorithms, Systems,\nand Applications (2016), Springer, pp. 250–261.\n[24] W ARNER , S. L. Randomized response: A sur-\nvey technique for eliminating evasive answer bias.\nJournal of the American Statistical Association 60,\n309 (1965), 63–69.\nA Additional Evaluation\nThis section provides additional experimental evaluation\nresults. We first try to measure average squared variance\non other datasets. Although RAPPOR did not specify a\nparticular optimal setting, we vary the number of cohorts\nand find differences. In the end, we evaluate different\nmethods on the Rockyou dataset.\nA.1 Effect of Cohort Size\nIn [13], the authors did not identify the best cohort size\nto use. Intuitively, if there are too few cohorts, many val-\nues will be hashed to be the same in the Bloom filter,\nmaking it difficult to distinguish these values. If there\nare more cohorts, each cohort cannot convey enough use-\nful information. Here we try to test what cohort size we\nshould use. We generate 10 million values following the\nZipf’s distribution (with parameter 1.5), but only use the\nfirst 128 most frequent values because of memory limita-\ntion caused by regression part of RAPPOR. We then run\nRAPPOR using 8, 16, 32, and 64, and 128 cohorts. We\nmeasure the average squared errors of queries about the\ntop 10 values, and the results are shown in Figure 7. As\nwe can see, more cohorts does not necessarily help lower\nthe squared error because the reduced probability of col-\nlision within each cohort. But it also has the disadvan-\ntage that each cohort may have insufficient information.\nIt can be seen OLH still performs best.\nA.2 Performance on Synthetic Datasets\nIn Figure 6, we test performance of different methods on\nsynthetic datasets. We generate 10 million points follow-\ning a normal distribution (rounded to integers, with mean\n500 and standard deviation 10) and a Zipf’s distribution\n(with parameter 1.5). The values range from 0 to 1000.\nWe then test the average squared errors on the most fre-\nquent 100 values. It can be seen that different methods\nperform similarly in different distributions. RAPPOR us-\ning 16 cohorts performs better than BLH. This is be-\ncause when the number of cohort is enough, each user in\na sense has his own hash functions. This can be viewed\nas a kind of local hashing function. When we only test\nthe top 10 values instead of top 50, RAP(16) and BLH\nperform similarly. Note that OLH performs best among\nall distributions.\nA.3 Performance on Rockyou Dataset\nWe run experiments on theRockyou dataset, which con-\ntains 21 million users’ password in plaintext. We first\nhash the plaintext into 20 bits, and use OLH, BLH, and\nBasic RAPPOR (also known as SUE in our framework)\nto test all hashed values. It can be seen that OLH per-\nforms best in all settings, and basic RAPPOR outper-\nforms BLH consistently. When ε = 4, and threshold is\n6000, OLH can recover around 50 true frequent hashes\nand 10 of false positives, which is 4 and 2 magnitudes\nsmaller than BLH and basic RAPPOR, respectively. The\nadvantage is not significant when ε is small, since the\nvariance difference is small.\nUSENIX Association 26th USENIX Security Symposium    743"
    },
    {
      "page_number": 17,
      "text": "105\n106\n107\n108\n109\n 0.5  1  1.5  2  2.5  3  3.5  4  4.5  5\nVar\nε\nOLH\nBLH\nRAP(8)\nRAP(16)\n(a) Zipf’s Top 100 Values\n105\n106\n107\n108\n109\n 0.5  1  1.5  2  2.5  3  3.5  4  4.5  5\nVar\nε\nOLH\nBLH\nRAP(8)\nRAP(16) (b) Normal Top 100 Values\n105\n106\n107\n108\n109\n 0.5  1  1.5  2  2.5  3  3.5  4  4.5  5\nVar\nε\nOLH\nBLH\nRAP(8)\nRAP(16)\n(c) Zipf’s Top 50 Values\n105\n106\n107\n108\n109\n 0.5  1  1.5  2  2.5  3  3.5  4  4.5  5\nVar\nε\nOLH\nBLH\nRAP(8)\nRAP(16) (d) Zipf’s Top 10 Values\nFigure 6: Average squared errors on estimating a distribution of 10 million points. RAPPOR is used with 128-bit\nlong Bloom filter and 2 hash functions.\n105\n106\n107\n108\n109\n 0.5  1  1.5  2  2.5  3  3.5  4  4.5  5\nVar\nε\nRAP(8)\nRAP(16)\nRAP(32)\nRAP(64)\nRAP(128)\nOLH\nFigure 7: Average squared error on estimating a normal\ndistribution of 1 million points. RAPPOR is used with\n128-bit long Bloom filter and 2 hash functions.\n744    26th USENIX Security Symposium USENIX Association"
    },
    {
      "page_number": 18,
      "text": " 30\n 40\n 50\n 60\n 70\n 80\n 5000  5500  6000  6500\nTP\nThreshold\nOLH BLH BasicRAP\n(a) Number of True Positives ε = 4\n100\n101\n102\n103\n104\n105\n106\n 5000  5500  6000  6500\nFP\nThreshold\nOLH BLH BasicRAP (b) Number of False Positives ε = 4\n 4\n 5\n 6\n 7\n 8\n 9\n 15000  20000  25000\nTP\nThreshold\nOLH BLH BasicRAP\n(c) Number of True Positives ε = 2\n100\n101\n102\n103\n104\n105\n 15000  20000  25000\nFP\nThreshold\nOLH BLH BasicRAP (d) Number of False Positives ε = 2\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n 20000  30000  40000  50000\nTP\nThreshold\nOLH BLH BasicRAP\n(e) Number of True Positives ε = 1\n100\n101\n102\n103\n104\n105\n 20000  30000  40000  50000\nFP\nThreshold\nOLH BLH BasicRAP (f) Number of False Positives ε = 1\nFigure 8: Results on Rockyou dataset for ε = 4,2 and 1. The y axes are the number of identified hash values that is\ntrue/false positive. The x axes are the threshold.\nUSENIX Association 26th USENIX Security Symposium    745"
    },
    {
      "page_number": 19,
      "text": ""
    }
  ],
  "full_text": "This paper is included in the Proceedings of the \n26th USENIX Security Symposium\nAugust 16–18, 2017 • Vancouver, BC, Canada\nISBN 978-1-931971-40 -9\nOpen access to the Proceedings of the \n26th USENIX Security Symposium \nis sponsored by USENIX\nLocally Differentially Private Protocols  \nfor Frequency Estimation\nTianhao Wang, Jeremiah Blocki, and Ninghui Li, Purdue University;  \nSomesh Jha, University of Wisconsin Madison\nhttps://www.usenix.org/conference/usenixsecurity17/technical-sessions/presentation/wang-tianhao\n\nLocally Differentially Private Protocols for Frequency Estimation\nTianhao Wang, Jeremiah Blocki, Ninghui Li\nPurdue University\nSomesh Jha\nUniversity of Wisconsin-Madison\nAbstract\nProtocols satisfying Local Differential Privacy (LDP) en-\nable parties to collect aggregate information about a pop-\nulation while protecting each user’s privacy, without re-\nlying on a trusted third party. LDP protocols (such as\nGoogle’s RAPPOR) have been deployed in real-world\nscenarios. In these protocols, a user encodes his pri-\nvate information and perturbs the encoded value locally\nbefore sending it to an aggregator, who combines val-\nues that users contribute to infer statistics about the pop-\nulation. In this paper, we introduce a framework that\ngeneralizes several LDP protocols proposed in the liter-\nature. Our framework yields a simple and fast aggre-\ngation algorithm, whose accuracy can be precisely ana-\nlyzed. Our in-depth analysis enables us to choose opti-\nmal parameters, resulting in two new protocols (i.e., Op-\ntimized Unary Encoding and Optimized Local Hashing)\nthat provide better utility than protocols previously pro-\nposed. We present precise conditions for when each pro-\nposed protocol should be used, and perform experiments\nthat demonstrate the advantage of our proposed proto-\ncols.\n1 Introduction\nDifferential privacy [10, 11] has been increasingly ac-\ncepted as the de facto standard for data privacy in the\nresearch community. While many differentially private\nalgorithms have been developed for data publishing and\nanalysis [12, 19], there have been few deployments of\nsuch techniques. Recently, techniques for satisfying dif-\nferential privacy (DP) in the local setting, which we\ncall LDP, have been deployed. Such techniques enable\ngathering of statistics while preserving privacy of every\nuser, without relying on trust in a single data curator.\nFor example, researchers from Google developed RAP-\nPOR [13, 16], which is included as part of Chrome. It\nenables Google to collect users’ answers to questions\nsuch as the default homepage of the browser, the default\nsearch engine, and so on, to understand the unwanted\nor malicious hijacking of user settings. Apple [1] also\nuses similar methods to help with predictions of spelling\nand other things, but the details of the algorithm are not\npublic yet. Samsung proposed a similar system [21]\nwhich enables collection of not only categorical answers\n(e.g., screen resolution) but also numerical answers (e.g.,\ntime of usage, battery volume), although it is not clear\nwhether this has been deployed by Samsung.\nA basic goal in the LDP setting is frequency estima-\ntion. A protocol for doing this can be broken down\ninto following steps: For each question, each user en-\ncodes his or her answer (called input) into a specific for-\nmat, randomizes the encoded value to get an output, and\nthen sends the output to the aggregator, who then aggre-\ngates and decodes the reported values to obtain, for each\nvalue of interest, an estimate of how many users have that\nvalue. With improvement on the basic task of frequency\nestimation, solutions to more complex problems that rely\non it, such as heavy hitter identification, frequent itemset\nmining, can also be improved.\nWe introduce a framework for what we call “pure”\nLDP protocols, which has a nice symmetric property.\nWe introduce a simple, generic aggregation and decod-\ning technique that works for all pure LDP protocols, and\nprove that this technique results in an unbiased estimate.\nWe also present a formula for the variance of the esti-\nmate. Most existing protocols fit our proposed frame-\nwork. The framework also enables us to precisely ana-\nlyze and compare the accuracy of different protocols, and\ngeneralize and optimize them. For example, we show\nthat the Basic RAPPOR protocol [13], which essentially\nuses unary encoding of input, chooses sub-optimal pa-\nrameters for the randomization step. Optimizing the pa-\nrameters results in what we call the Optimized Unary\nEncoding (OUE) protocol, which has significantly bet-\nter accuracy.\nProtocols based on unary encoding require Θ(d) com-\nUSENIX Association 26th USENIX Security Symposium    729\n\nmunication cost, where d is the number of possible in-\nput values, and can be very large (or even unbounded)\nfor some applications. The RAPPOR protocol uses a\nBloom filter encoding to reduce the communication cost;\nhowever, this comes with a cost of decreasing accuracy\nas well as increasing computation cost for aggregation\nand decoding. The random matrix projection-based ap-\nproach introduced in [6] has Θ(logn) communication\ncost (where n is the number of users); however, its accu-\nracy is unsatisfactory. We observe that in our framework\nthis protocol can be interpreted as binary local hash-\ning. Generalizing this and optimizing the parameters re-\nsults in a new Optimized Local Hashing (OLH) protocol,\nwhich provides much better accuracy while still requir-\ning Θ(logn) communication cost. The variance of OLH\nis orders of magnitude smaller than the previous meth-\nods, for ε values used in RAPPOR’s implementation. In-\nterestingly, OLH has the same error variance as OUE;\nthus it reduces communication cost at no cost of utility.\nWith LDP, it is possible to collect data that was in-\naccessible because of privacy issues. Moreover, the in-\ncreased amount of data will significantly improve the\nperformance of some learning tasks. Understanding cus-\ntomer statistics help cloud server and software platform\noperators to better understand the needs of populations\nand offer more effective and reliable services. Such\nprivacy-preserving crowd-sourced statistics are also use-\nful for providing better security while maintaining a level\nof privacy. For example, in [13], it is demonstrated\nthat such techniques can be applied to collecting win-\ndows process names and Chrome homepages to discover\nmalware processes and unexpected default homepages\n(which could be malicious).\nOur paper makes the following contributions:\n• We introduce a framework for “pure” LDP proto-\ncols, and develop a simple, generic aggregation and\ndecoding technique that works for all such proto-\ncols. This framework enables us to analyze, gener-\nalize, and optimize different LDP protocols.\n• We introduce the Optimized Local Hashing (OLH)\nprotocol, which has low communication cost and\nprovides much better accuracy than existing proto-\ncols. For ε ≈ 4, which was used in the RAPPOR\nimplementation, the variance of OLH’s estimation\nis 1/2 that of RAPPOR, and close to 1 /14 that of\nRandom Matrix Projection [6]. Systems using LDP\nas a primitive could benefit significantly by adopt-\ning improved LDP protocols like OLH.\nRoadmap. In Section 2, we describe existing proto-\ncols from [13, 6]. We then present our framework for\npure LDP protocols in Section 3, apply it to study LDP\nprotocols in Section 4, and compare different LDP proto-\ncols in Section 5. We show experimental results in Sec-\ntion 6. We review related work in Section 7, discuss in\nSection 8, and conclude in Section 9.\n2 Background and Existing Protocols\nThe notion of differential privacy was originally intro-\nduced for the setting where there is a trusted data cu-\nrator, who gathers data from individual users, processes\nthe data in a way that satisfies DP, and then publishes the\nresults. Intuitively, the DP notion requires that any sin-\ngle element in a dataset has only a limited impact on the\noutput.\nDefinition 1 (Differential Privacy) An algorithm A\nsatisfies ε-differential privacy ( ε-DP), where ε ≥ 0, if\nand only if for any datasets D and D ′ that differ in one\nelement, we have\n∀t ∈Range(A) : Pr[A(D) =t] ≤ eε Pr\n[\nA(D′) =t\n]\n,\nwhere Range(A) denotes the set of all possible outputs\nof the algorithm A.\n2.1 Local Differential Privacy Protocols\nIn the local setting, there is no trusted third party. Anag-\ngregator wants to gather information from users. Users\nare willing to help the aggregator, but do not fully trust\nthe aggregator for privacy. For the sake of privacy, each\nuser perturbs her own data before sending it to the aggre-\ngator (via a secure channel). For this paper, we consider\nthat each user has a single value v, which can be viewed\nas the user’s answer to a given question. The aggrega-\ntor aims to find out the frequencies of values among the\npopulation. Such a data collection protocol consists of\nthe following algorithms:\n• Encode is executed by each user. The algorithm\ntakes an input value v and outputs an encoded value\nx.\n• Perturb, which takes an encoded value x and out-\nputs y. Each user with value v reports y =\nPerturb(Encode(v)). For compactness, we use\nPE(·) to denote the composition of the encod-\ning and perturbation algorithms, i.e., PE(·) =\nPerturb(Encode(·)). PE(·) should satisfy ε-local\ndifferential privacy, as defined below.\n• Aggregate is executed by the aggregator; it takes all\nthe reported values, and outputs aggregated infor-\nmation.\nDefinition 2 (Local Differential Privacy) An algo-\nrithm A satisfies ε-local differential privacy ( ε-LDP),\n730    26th USENIX Security Symposium USENIX Association\n\nwhere ε ≥ 0, if and only if for any input v 1 and v2, we\nhave\n∀y ∈ Range(A) : Pr[A(v1) =y] ≤ eε Pr[A(v2) =y],\nwhere Range(A) denotes the set of all possible outputs\nof the algorithm A.\nThis notion is related to randomized response [24],\nwhich is a decades-old technique in social science to col-\nlect statistical information about embarrassing or illegal\nbehavior. To report a single bit by random response, one\nreports the true value with probabilityp and the flip of the\ntrue value with probability 1−p. This satisfies\n(\nln p\n1−p\n)\n-\nLDP.\nComparing to the setting that requires a trusted data\ncurator, the local setting offers a stronger level of pro-\ntection, because the aggregator sees only perturbed data.\nEven if the aggregator is malicious and colludes with all\nother participants, one individual’s private data is still\nprotected according to the guarantee of LDP.\nProblem Definition and Notations. There are n users.\nEach user j has one value vj and reports once. We use d\nto denote the size of the domain of the values the users\nhave, and [d] to denote the set {1,2,..., d}. Without loss\nof generality, we assume the input domain is [d]. The\nmost basic goal of Aggregate is frequency estimation,\ni.e., estimate, for a given value i ∈ [d], how many users\nhave the value i. Other goals have also been considered\nin the literature. One goal is, when d is very large, iden-\ntify values in [d] that are frequent, without going through\nevery value in [d] [16, 6]. In this paper, we focus on fre-\nquency estimation. This is the most basic primitive and is\na necessary building block for all other goals. Improving\nthis will improve effectiveness of other protocols.\n2.2 Basic RAPPOR\nRAPPOR [13] is designed to enable longitudinal collec-\ntions, where the collection happens multiple times. In-\ndeed, Chrome’s implementation of RAPPOR [3] collects\nanswers to some questions once every 30 minutes. Two\nprotocols, Basic RAPPOR and RAPPOR, are proposed\nin [13]. We first describe Basic RAPPOR.\nEncoding. Encode(v) =B0, where B0 is a length-d bi-\nnary vector such that B0[v] =1 and B0[i] =0 for i ̸= v.\nWe call this Unary Encoding.\nPerturbation. Perturb(B0) consists of two steps:\nStep 1: Permanent randomized response: Generate B1\nsuch that:\nPr[B1[i] =1] =\n{\n1 − 1\n2 f , if B0[i] =1,\n1\n2 f , if B0[i] =0.\nRAPPOR’s implementation uses f = 1/2 and f = 1/4.\nNote that this randomization is symmetric in the sense\nthat Pr[B1[i] =1|B0[i] =1] =Pr[B1[i] =0|B0[i] =0] =\n1 − 1\n2 f ; that is, the probability that a bit of 1 is preserved\nequals the probability that a bit of 0 is preserved. This\nstep is carried out only once for each value v that the\nuser has.\nStep 2: Instantaneous randomized response: Report B2\nsuch that:\nPr[B2[i] =1] =\n{\np, if B1[i] =1,\nq, if B1[i] =0.\nThis step is carried out each time a user reports the value.\nThat is, B1 will be perturbed to generate differentB2’s for\neach reporting. RAPPOR’s implementation [5] uses p =\n0.75 and q = 0.25, and is hence also symmetric because\np +q = 1.\nWe note that as both steps are symmetric, their com-\nbined effect can also be modeled by a symmetric ran-\ndomization. Moreover, we study the problem where each\nuser only reports once. Thus without loss of generality,\nwe ignore the instantaneous randomized response step\nand consider only the permanent randomized response\nwhen trying to identify effective protocols.\nAggregation. Let Bj be the reported vector of the j-th\nuser. Ignoring the Instantaneous randomized response\nstep, to estimate the number of times i occurs, the aggre-\ngator computes:\n˜c(i) =∑j 1 {i|Bj[i]=1}(i)− 1\n2 f n\n1 − f\nThat is, the aggregator first counts how many timei is re-\nported by computing ∑j 1 {i|Bj[i]=1}(i), which counts how\nmany reported vectors have the i’th bit being 1, and then\ncorrects for the effect of randomization. We use 1 X (i) to\ndenote the indicator function such that:\n1 X (i) =\n{\n1, if i ∈ X,\n0, if i /∈ X.\nCost. The communication and computing cost is Θ(d)\nfor each user, and Θ(nd) for the aggregator.\nPrivacy. Against an adversary who may observe\nmultiple transmissions, this achieves ε-LDP for ε =\nln\n((\n1−1\n2 f\n1\n2 f\n)2)\n, which is ln9 for f = 1/2 and ln49 for\nf = 1/4.\n2.3 RAPPOR\nBasic RAPPOR uses unary encoding, and does not scale\nwhen d is large. To address this problem, RAPPOR uses\nBloom filters [7]. While Bloom filters are typically used\nUSENIX Association 26th USENIX Security Symposium    731\n\nto encode a set for membership testing, in RAPPOR it is\nused to encode a single element.\nEncoding. Encoding uses a set of m hash functions\nH = {H1,H2,..., Hm}, each of which outputs an integer\nin [k] ={0,1,..., k −1}. Encode(v) =B0, which is k-bit\nbinary vector such that\nB0[i] =\n{\n1, if ∃H ∈ H,s.t.,H(v) =i,\n0, otherwise.\nPerturbation. The perturbation process is identical to\nthat of Basic RAPPOR.\nAggregation. The use of shared hashing creates chal-\nlenges due to potential collisions. If two values happen\nto be hashed to the same set of indices, it becomes im-\npossible to distinguish them. To deal with this problem,\nRAPPOR introduces the concept of cohorts. The users\nare divided into a number of cohorts. Each cohort uses a\ndifferent set of hash functions, so that the effect of col-\nlisions is limited to within one cohort. However, par-\ntial collisions, i.e., two values are hashed to overlapping\n(though not identical) sets of indices, can still occur and\ninterfere with estimation. These complexities make the\naggregation algorithm more complicated. RAPPOR uses\nLASSO and linear regression to estimate frequencies of\nvalues.\nCost. The communication and computing cost is Θ(k)\nfor each user. The aggregator’s computation cost is\nhigher than Basic RAPPOR due to the usage of LASSO\nand regression.\nPrivacy. RAPPOR achieves ε-LDP for ε =\nln\n((\n1−1\n2 f\n1\n2 f\n)2m)\n. The RAPPOR implementation\nuses m = 2; thus this is ln81 ≈ 4.39 for f = 1/2 and\nln74 ≈ 7.78 for f = 1/4.\n2.4 Random Matrix Projection\nBassily and Smith [6] proposed a protocol that uses ran-\ndom matrix projection. This protocol has an additional\nSetup step.\nSetup. The aggregator generates a public matrix Φ ∈\n{− 1√m , 1√m }m×d uniformly at random. Here m is a pa-\nrameter determined by the error bound, where the “error”\nis defined as the maximal distance between the estima-\ntion and true frequency of any domain.\nEncoding. Encode(v) =⟨r,x⟩, where r is selected uni-\nformly at random from [m], and x is the v’s element of\nthe r’s row of Φ, i.e., x = Φ[r,v].\nPerturbation. Perturb(⟨r,x⟩) =⟨r, b ·c ·m ·x⟩, where\nb =\n{\n1 with probability p = eε\neε +1 ,\n−1 with probability q = 1\neε +1 ,\nc = (eε +1)/(eε −1).\nAggregation. Given reports ⟨r j,yj⟩’s, the estimate for\ni ∈ [d] is given by\n˜c(i) =∑\nj\nyj ·Φ[r j,i].\nThe effect is that each user with input value i contributes\nc to ˜c(i) with probability p, and −c with probability q;\nthus the expected contribution is\n(p −q)·c =\n( eε\neε +1 − 1\neε +1\n)\n· eε +1\neε −1 = 1.\nBecause of the randomness inΦ, each user with value̸= i\ncontributes to ˜c(i) either c or −c, each with probability\n1/2; thus the expected contribution from all such users\nis 0. Note that each row in the matrix is essentially a\nrandom hashing function mapping each value in [d] to a\nsingle bit. Each user selects such a hash function, uses it\nto hash her value into one bit, and then perturbs this bit\nusing random response.\nCost. A straightforward implementation of the protocol\nis expensive. However, the public random matrixΦ does\nnot need to be explicitly computed. For example, using\na common pseudo-random number generator, each user\ncan randomly choose a seed to generate a row in the ma-\ntrix and send the seed in her report. With this technique,\nthe communication cost is Θ(logm) for each user, and\nthe computation cost is O(d) for computing one row of\nthe Φ. The aggregator needs Θ(dm) to generate Φ, and\nΘ(md) to compute the estimations.\n3 A Framework for LDP Protocols\nMultiple protocols have been proposed for estimating\nfrequencies under LDP, and one can envision other pro-\ntocols. A natural research question is how do they com-\npare with each other? Under the same level of privacy,\nwhich protocol provides better accuracy in aggregation,\nwith lower cost? Can we come up with even better ones?\nTo answer these questions, we define a class of LDP pro-\ntocols that we call “pure”.\nFor a protocol to be pure, we require the specifica-\ntion of an additional function Support, which maps each\npossible output y to a set of input values that y “sup-\nports”. For example, in the basic RAPPOR protocol, an\noutput binary vector B is interpreted as supporting each\n732    26th USENIX Security Symposium USENIX Association\n\ninput whose corresponding bit is 1, i.e., Support(B) =\n{i | B[i] =1}.\nDefinition 3 (Pure LDP Protocols) A protocol given by\nPE and Support is pure if and only if there exist two prob-\nability values p∗ > q∗ such that for all v1,\nPr[PE(v1) ∈ {y | v1 ∈ Support(y)}] =p∗,\n∀v2̸=v1 Pr[PE(v2) ∈ {y | v1 ∈ Support(y)}] =q∗.\nA pure protocol is in some sense “pure and simple”. For\neach input v1, the set {y | v1 ∈ Support(y)} identifies all\noutputs y that “support” v1, and can be called the support\nset of v1. A pure protocol requires the probability that\nany value v1 is mapped to its own support set be the same\nfor all values. We use p∗ to denote this probability. In\norder to satisfy LDP, it must be possible for a valuev2 ̸=\nv1 to be mapped to v1’s support set. It is required that\nthis probability, which we use q∗ to denote, must be the\nsame for all pairs of v1 and v2. Intuitively, we want p∗ to\nbe as large as possible, and q∗ to be as small as possible.\nHowever, satisfying ε-LDP requires that p∗\nq∗ ≤ eε .\nBasic RAPPOR is pure with p∗ = 1 − f\n2 and q∗ = f\n2 .\nRAPPOR is not pure because there does not exist a suit-\nable q∗ due to collisions in mapping values to bit vec-\ntors. Assuming the use of two hash functions, if v1 is\nmapped to [1,1,0,0], v2 is mapped to [1,0,1,0], and v3 is\nmapped to [0,0,1,1], then because [1,1,0,0] differs from\n[1,0,1,0] by only two bits, and from [0,0,1,1] by four\nbits, the probability that v2 is mapped to v1’s support set\nis higher than that ofv3 being mapped to v1’s support set.\nFor a pure protocol, let yj denote the submitted value\nby user j, a simple aggregation technique to estimate the\nnumber of times that i occurs is as follows:\n˜c(i) =∑j 1 Support(yj)(i)−nq∗\np∗ −q∗ (1)\nThe intuition is that each output that supports i gives an\ncount of 1 for i. However, this needs to be normalized,\nbecause even if every input is i, we only expect to see\nn · p∗ outputs that support i, and even if input i never\noccurs, we expect to see n ·q∗ supports for it. Thus the\noriginal range of 0 to n is “compressed” into an expected\nrange of nq∗ to np∗. The linear transformation in (1)\ncorrects this effect.\nTheorem 1 For a pure LDP protocol PE and Support,\n(1) is unbiased, i.e., ∀iE[ ˜c(i)] =n fi, where fi is the frac-\ntion of times that the value i occurs.\nProof 1\nE[ ˜c(i)] =E\n⎡\n⎣\n(\n∑j 1 Support(yj)(i)\n)\n−nq∗\np∗ −q∗\n⎤\n⎦\n=n fi p∗ +n(1 − fi)q∗ −nq∗\np∗ −q∗\n=n · fi p∗ +q∗ − fiq∗ −q∗\np∗ −q∗\n=n fi\nThe variance of the estimator in 1 is a valuable indi-\ncator of an LDP protocol’s accuracy:\nTheorem 2 For a pure LDP protocol PE and Support,\nthe variance of the estimation ˜c(i) in (1) is:\nVar[˜c(i)] =nq∗(1 −q∗)\n(p∗ −q∗)2 + n fi(1 − p∗ −q∗)\np∗ −q∗ (2)\nProof 2 The random variable ˜c(i) is the (scaled) sum-\nmation of n independent random variables drawn from\nthe Bernoulli distribution. More specifically, n f i (resp.\n(1 − fi)n) of these random variables are drawn from\nthe Bernoulli distribution with parameter p ∗ (resp. q ∗).\nThus,\nVar[˜c(i)] =Var\n⎡\n⎣\n(\n∑j 1 Support(yj)(i)\n)\n−nq∗\np∗ −q∗\n⎤\n⎦\n= ∑j Var[1 Support(yj)(i)]\n(p∗ −q∗)2\n= n fi p∗(1 − p∗)+ n(1 − fi)q∗(1 −q∗)\n(p∗ −q∗)2\n= nq∗(1 −q∗)\n(p∗ −q∗)2 + n fi(1 − p∗ −q∗)\np∗ −q∗ (3)\nIn many application domains, the vast majority of val-\nues appear very infrequently, and one wants to identify\nthe more frequent ones. The key to avoid having lots of\nfalse positives is to have low estimation variances for the\ninfrequent values. When fi is small, the variance in (2) is\ndominated by the first term. We use Var ∗ to denote this\napproximation of the variance, that is:\nVar∗[˜c(i)] =nq∗(1 −q∗)\n(p∗ −q∗)2 (4)\nWe also note that some protocols have the property that\np∗ +q∗ = 1, in which case Var∗ = Var.\nAs the estimation ˜c(i) is the sum of many independent\nrandom variables, its distribution is very close to a nor-\nmal distribution. Thus, the mean and variance of ˜ c(i)\nfully characterizes the distribution of ˜ c(i) for all prac-\ntical purposes. When comparing different methods, we\nobserve that fixing ε, the differences are reflected in the\nconstants for the variance, which is where we focus our\nattention.\nUSENIX Association 26th USENIX Security Symposium    733\n\n4 Optimizing LDP Protocols\nWe now cast many protocols that have been proposed\ninto our framework of “pure” LDP protocols. Casting\nthese protocols into the framework of pure protocols en-\nables us to derive their variances and understand how\neach method’s accuracy is affected by parameters such\nas domain size, ε, etc. This also enables us to general-\nize and optimize these protocols and propose two new\nprotocols that improve upon existing ones. More specifi-\ncally, we will consider the following protocols, which we\norganize by their encoding methods.\n• Direct Encoding (DE).There is no encoding. It is a\ngeneralization of the Random Response technique.\n• Histogram Encoding (HE). An input v is encoded\nas a histogram for thed possible values. The pertur-\nbation step adds noise from the Laplace distribution\nto each number in the histogram. We consider two\naggregation techniques, SHE and THE.\n– Summation with Histogram Encoding\n(SHE) simply sums up the reported noisy\nhistograms from all users.\n– Thresholding with Histogram Encoding\n(THE) is parameterized by a value θ; it inter-\nprets each noisy count above a threshold θ as\na 1, and each count below θ as a 0.\n• Unary Encoding (UE). An input v is encoded as a\nlength-d bit vector, with only the bit corresponding\nto v set to 1. Here two key parameters in perturba-\ntion are p, the probability that 1 remains 1 after per-\nturbation, and q, the probability that 0 is perturbed\ninto 1. Depending on their choices, we have two\nprotocols, SUE and OUE.\n– Symmetric Unary Encoding ( SUE) uses p +\nq = 1; this is the Basic RAPPOR proto-\ncol [13].\n– Optimized Unary Encoding ( OUE) uses op-\ntimized choices of p and q; this is newly pro-\nposed in this paper.\n• Local Hashing (LH). An input v is encoded by\nchoosing at random H from a universal hash func-\ntion family H, and then outputting (H,H(v)). This\nis called Local Hashing because each user chooses\nindependently the hash function to use. Here a key\nparameter is the range of these hash functions. De-\npending on this range, we have two protocols, BLH\nand OLH.\n– Binary Local Hashing (BLH) uses hash func-\ntions that outputs a single bit. This is equiva-\nlent to the random matrix projection technique\nin [6].\n– Optimized Local Hashing ( OLH) uses opti-\nmized choices for the range of hash functions;\nthis is newly proposed in this paper.\n4.1 Direct Encoding (DE)\nOne natural method is to extend the binary response\nmethod to the case where the number of input values is\nmore than 2. This is used in [23].\nEncoding and Perturbing. EncodeDE(v) = v, and\nPerturb is defined as follows.\nPr[PerturbDE(x) =i] =\n{\np = eε\neε +d−1 , if i = x\nq = 1−p\nd−1 = 1\neε +d−1 , if i ̸= x\nTheorem 3 (Privacy of DE) The Direct Encoding (DE)\nProtocol satisfies ε-LDP .\nProof 3 For any inputs v1,v2 and output y, we have:\nPr[PEDE(v1) =y]\nPr[PEDE(v2) =y] ≤ p\nq = eε /(eε +d −1)\n1/(eε +d −1) = eε\nAggregation. Let the Support function for DE be\nSupportDE(i) ={i}, i.e., each output value i supports\nthe input i. Then this protocol is pure, with p∗ = p and\nq∗ = q. Plugging these values into (4), we have\nVar∗[˜cDE(i)] =n · d −2 +eε\n(eε −1)2\nNote that the variance given above is linear in nd. As d\nincreases, the accuracy of DE suffers. This is because,\nas d increases, p = eε\neε +d−1 , the probability that a value\nis transmitted correctly, becomes smaller. For example,\nwhen eε = 49 and d = 216, we have p = 49\n65584 ≈ 0.00075.\n4.2 Histogram Encoding (HE)\nIn Histogram Encoding (HE), an inputx ∈ [d] is encoded\nusing a length-d histogram.\nEncoding. EncodeHE(v) = [0.0,0.0,··· ,1.0,··· ,0.0],\nwhere only the v-th component is 1.0. Two different in-\nput v values will result in two vectors that have L1 dis-\ntance of 2.0.\nPerturbing. PerturbHE(B) outputs B′ such that B′[i] =\nB[i]+ Lap\n(2\nε\n)\n, where Lap(β) is the Laplace distribution\nwhere Pr[Lap(β) =x] = 1\n2β e−|x|/β .\nTheorem 4 (Privacy of HE) The Histogram Encoding\nprotocol satisfies ε-LDP .\nProof 4 For any inputs v1,v2, and output B, we have\nPr[B|v1]\nPr[B|v2] =\n∏i∈[d] Pr[B[i]|v1]\n∏i∈[d] Pr[B[i]|v2] = Pr[B[v1]|v1]Pr[B[v2]|v1]\nPr[B[v1]|v2]Pr[B[v2]|v2]\n≤ eε/2 ·eε/2 = eε\n734    26th USENIX Security Symposium USENIX Association\n\nAggregation: Summation with Histogram Encoding\n(SHE) works as follows: For each value, sum the noisy\ncounts for that value reported by all users. That is,\n˜cSHE(i) =∑j Bj[i], where Bj is the noisy histogram re-\nceived from user j. This aggregation method does not\nprovide a Support function and is not pure. We prove its\nproperty as follows.\nTheorem 5 In SHE, the estimation ˜cSHE is unbiased.\nFurthermore, the variance is\nVar[ ˜cSHE(i)] =n 8\nε2\nProof 5 Since the added noise is 0-mean; the expected\nvalue of the sum of all noisy counts is the true count.\nThe Lap(β) distribution has variance 2\nβ2 , since β = ε\n2\nfor each B j[i], then the variance of each such variable\nis 8\nε2 , and the sum of n such independent variables have\nvariance n 8\nε2 .\nAggregation: Thresholding with Histogram Encod-\ning (THE) interprets a vector of noisy counts discretely\nby defining\nSupportTHE(B) ={v | B[v] > θ}\nThat is, each noise count that is > θ supports the corre-\nsponding value. This thresholding step can be performed\neither by the user or by the aggregator. It does not ac-\ncess the original value, and thus does not affect the pri-\nvacy guarantee. Using thresholding to provide aSupport\nfunction makes the protocol pure. The probabilityp∗ and\nq∗ are given by\np∗ = 1 −F(θ −1); q∗ = 1 −F(θ),\nwhere F(x) =\n{ 1\n2 e\nε\n2 x, if x < 0\n1 − 1\n2 e−ε\n2 x, if x ≥ 0\nHere, F(·) is the cumulative distribution function of\nLaplace distribution. If 0 ≤ θ ≤ 1, then we have\np∗ = 1 − 1\n2e\nε\n2 (θ−1); q∗ = 1\n2e−ε\n2 θ .\nPlugging these values into (4), we have\nVar∗[˜cHET(i)] =n · 2eεθ /2 −1\n(1 +eε(θ−1/2) −2eεθ /2)2\nComparing SHE and THE. Fixing ε, one can choose\na θ value to minimize the variance. Numerical analy-\nsis shows that the optimal θ is in (1\n2 ,1), and depends on\nε. When ε is large, θ → 1. Furthermore, Var [˜cTHE] <\nVar[˜cSHE] is always true. This means that by thresh-\nolding, one improves upon directly summing up noisy\ncounts, likely because thresholding limits the impact of\nnoises of large magnitude. In Section 5, we illustrate the\ndifferences between them using actual numbers.\n4.3 Unary Encoding (UE)\nBasic RAPPOR, which we described in Section 2.2,\ntakes the approach of directly perturbing a bit vector. We\nnow explore this method further.\nEncoding. Encode(v) = [0,··· ,0,1,0,··· ,0], a length-d\nbinary vector where only the v-th position is 1.\nPerturbing. Perturb(B) outputs B′ as follows:\nPr\n[\nB′[i] =1\n]\n=\n{\np, if B[i] =1\nq, if B[i] =0\nTheorem 6 (Privacy of UE) The Unary Encoding pro-\ntocol satisfies ε-LDP for\nε = ln\n(p(1 −q)\n(1 − p)q\n)\n(5)\nProof 6 For any inputs v1,v2, and output B, we have\nPr[B|v1]\nPr[B|v2] =∏i∈[d] Pr[B[i]|v1]\n∏i∈[d] Pr[B[i]|v2] (6)\n≤Pr[B[v1] =1|v1]Pr[B[v2] =0|v1]\nPr[B[v1] =1|v2]Pr[B[v2] =0|v2] (7)\n= p\nq · 1 −q\n1 − p = eε\n(6) is because each bit is flipped independently, and(7) is\nbecause v1 and v2 result in bit vectors that differ only in\nlocations v1 and v2, and a vector with position v 1 being\n1 and position v2 being 0 maximizes the ratio.\nAggregation. A reported bit vector is viewed as support-\ning an input i if B[i] =1, i.e., SupportUE(B) ={i | B[i] =\n1}. This yields p∗ = p and q∗ = q. Interestingly, (5)\ndoes not fully determine the values of p and q for a fixed\nε. Plugging (5) into (4), we have\nVar∗[˜cUE(i)] =nq(1 −q)\n(p −q)2 = nq(1 −q)\n( eε q\n1−q+eε q −q)2\n= n · ((eε −1)q +1)2\n(eε −1)2(1 −q)q. (8)\nSymmetric UE ( SUE). RAPPOR’s implementation\nchooses p and q such that p + q = 1; making the treat-\nment of 1 and 0 symmetric. Combining this with (5), we\nhave\np = eε/2\neε/2 +1, q = 1\neε/2 +1\nPlugging these into (8), we have\nVar∗[˜cSUE(i)] =n · eε/2\n(eε/2 −1)2\nUSENIX Association 26th USENIX Security Symposium    735\n\nOptimized UE (OUE). Instead of making p and q sym-\nmetric, we can choose them to minimize (8). Take the\npartial derivative of (8) with respect to q, and solving q\nto make the result 0, we get:\n∂\n[ ((eε −1)q+1)2\n(eε −1)2(1−q)q\n]\n∂q =\n∂\n[\n1\n(eε −1)2 ·\n((eε −1)2q\n1−q + 2(eε −1)\n1−q + 1\nq(1−q)\n)]\n∂q\n=\n∂\n[\n1\n(eε −1)2 ·\n(\n−(eε −1)2 + e2ε\n1−q + 1\nq\n)]\n∂q\n= 1\n(eε −1)2\n( e2ε\n(1 −q)2 − 1\nq2\n)\n= 0\n=⇒ 1 −q\nq = eε ,i.e.,q = 1\neε +1 and p = 1\n2\nPlugging p = 1\n2 and q = 1\neε +1 into (8), we get\nVar∗[˜cOUE(i)] =n 4eε\n(eε −1)2 (9)\nThe reason why setting p = 1\n2 and q = 1\neε +1 is opti-\nmal when the true frequencies are small may be unclear\nat first glance; however, there is an intuition behind it.\nWhen the true frequencies are small, d is large. Recall\nthat eε = p\n1−p\n1−q\nq . Setting p and q can be viewed as\nsplitting ε into ε1 +ε2 such that p\n1−p = eε1 and 1−q\nq = eε2 .\nThat is, ε1 is the privacy budget for transmitting the 1 bit,\nand ε2 is the privacy budget for transmitting each 0 bit.\nSince there are many 0 bits and a single 1 bit, it is better\nto allocate as much privacy budget for transmitting the 0\nbits as possible. In the extreme, settingε1 = 0 and ε2 = ε\nmeans that setting p = 1\n2 .\n4.4 Binary Local Hashing (BLH)\nBoth HE and UE use unary encoding and have Θ(d)\ncommunication cost, which is too large for some appli-\ncations. To reduce the communication cost, a natural\nidea is to first hash the input value into a domain of size\nk < d, and then apply the UE method to the hashed value.\nThis is the basic idea underlying the RAPPOR method.\nHowever, a problem with this approach is that two val-\nues may be hashed to the same output, making them in-\ndistinguishable from each other during decoding. RAP-\nPOR tries to address this in several ways. One is to use\nmore than one hash functions; this reduces the chance of\na collision. The other is to use cohorts, so that differ-\nent cohorts use different sets of hash functions. These\nremedies, however, do not fully eliminate the potential\neffect of collisions. Using more than one hash functions\nalso means that every individual bit needs to be perturbed\nmore to satisfy ε-LDP for the same ε.\nA better approach is to make each user belong to a co-\nhort by herself. We call this the local hashing approach.\nThe random matrix-base protocol in [6] (described in\nSection 2.4), in its very essence, uses a local hashing en-\ncoding that maps an input value to a single bit, which is\nthen transmitted using randomized response. Below is\nthe Binary Local Hashing (BLH) protocol, which is log-\nically equivalent to the one in Section 2.4, but is simpler\nand, we hope, better illustrates the essence of the idea.\nLet H be a universal hash function family, such that\neach hash function H ∈ H hashes an input in [d] into one\nbit. The universal property requires that\n∀x,y ∈ [d],x ̸= y : Pr\nH∈H\n[H(x) =H(y)] ≤ 1\n2.\nEncoding. EncodeBLH(v) =⟨H,b⟩, where H ←R H is\nchosen uniformly at random fromH, and b = H(v). Note\nthat the hash function H can be encoded using an index\nfor the family H and takes only O(logn) bits.\nPerturbing. PerturbBLH(⟨H,b⟩) =⟨H,b′⟩ such that\nPr\n[\nb′ = 1\n]\n=\n{\np = eε\neε +1 , if b = 1\nq = 1\neε +1 , if b = 0\nAggregation. SupportBLH(⟨H,b⟩) ={v | H(v) =b},\nthat is, each reported ⟨H,b⟩ supports all values that are\nhashed by H to b, which are half of the input values. Us-\ning this Support function makes the protocol pure, with\np∗ = p and q∗ = 1\n2 p+ 1\n2 q = 1\n2 . Plugging the values of p∗\nand q∗ into (4), we have\nVar∗[˜cBLH(i)] =n · (eε +1)2\n(eε −1)2 .\n4.5 Optimal Local Hashing (OLH)\nOnce the random matrix projection protocol is cast as\nbinary local hashing, we can clearly see that the encoding\nstep loses information because the output is just one bit.\nEven if that bit is transmitted correctly, we can get only\none bit of information about the input, i.e., to which half\nof the input domain does the value belong. When ε is\nlarge, the amount of information loss in the encoding step\ndominates that of the random response step. Based on\nthis insight, we generalize Binary Local Hashing so that\neach input value is hashed into a value in [g], where g ≥\n2. A larger g value means that more information is being\npreserved in the encoding step. This is done, however, at\na cost of more information loss in the random response\nstep. As in our analysis of the Direct Encoding method,\na large domain results in more information loss.\nLet H be a universal hash function family such that\neach H ∈ H outputs a value in [g].\nEncoding. Encode(v) =⟨H,x⟩, where H ∈ H is chosen\n736    26th USENIX Security Symposium USENIX Association\n\nuniformly at random, and x = H(v).\nPerturbing. Perturb(⟨H,x⟩) = (⟨H,y⟩), where\n∀i∈[g] Pr[y = i] =\n{\np = eε\neε +g−1 , if x = i\nq = 1\neε +g−1 , if x ̸= i\nTheorem 7 (Privacy of LH) The Local Hashing ( LH)\nProtocol satisfies ε-LDP\nProof 7 For any two possible input values v1,v2 and any\noutput ⟨H,y⟩, we have,\nPr[⟨H,y⟩|v1]\nPr[⟨H,y⟩|v2] = Pr[Perturb(H(v1)) =y]\nPr[Perturb(H(v2)) =y] ≤ p\nq = eε\nAggregation. Let SupportLH(⟨H,y⟩) ={i | H(i) =y},\ni.e., the set of values that are hashed into the reported\nvalue. This gives rise to a pure protocol with\np∗ = p and q∗ = 1\ng p + g −1\ng q = 1\ng.\nPlugging these values into (4), we have the\nVar∗[˜cLP(i)] =n · (eε −1 +g)2\n(eε −1)2(g −1). (10)\nOptimized LH (OLH) Now we find the optimal g\nvalue, by taking the partial derivative of (10) with respect\nto g.\n∂\n[\n(eε −1+g)2\n(eε −1)2(g−1)\n]\n∂g =\n∂\n[\ng−1\n(eε −1)2 + 1\ng−1 · e2ε\n(eε −1)2 + 2eε\n(eε −1)2\n]\n∂g\n= 1\n(eε −1)2 − 1\n(g −1)2 · e2ε\n(eε −1)2 = 0\n=⇒ g = eε +1\nWhen g = eε + 1, we have p∗ = eε\neε +g−1 = 1\n2 , q∗ = 1\ng =\n1\neε +1 into (8), and\nVar∗[˜cOLH(i)] =n · 4eε\n(eε −1)2 . (11)\nComparing OLH with OUE. It is interesting to observe\nthat the variance we derived for optimized local hashing\n(OLH), i.e., (11) is exactly that we have for optimized\nunary encoding (OUE), i.e., (9). Furthermore, the proba-\nbility values p∗ and q∗ are also exactly the same. This il-\nlustrates that OLH and OUE are in fact deeply connected.\nOLH can be viewed as a compact way of implementing\nOUE. Compared with OUE, OLH has communication\ncost O(logn) instead of O(d).\nThe fact that optimizing two apparently different en-\ncoding approaches, namely, unary encoding and lo-\ncal hashing, results in conceptually equivalent protocol,\nseems to suggest that this may be optimal (at least when\nd is large). However, whether this is the best possible\nprotocol remains an interesting open question.\n5 Which Protocol to Use\nWe have cast most of the LDP protocols proposed in the\nliterature into our framework of pure LDP protocols. Do-\ning so also enables us to generalize and optimize exist-\ning protocols. Now we are able to answer the question:\nWhich LDP protocol should one use in a given setting?\nGuideline. Table 1 lists the major parameters for the dif-\nferent protocols. Histogram encoding and unary encod-\ning requires Θ(d) communication cost, and is expensive\nwhen d is large. Direct encoding and local hashing re-\nquire Θ(logd) or Θ(logn) communication cost, which\namounts to a constant in practice. All protocols other\nthan DE have O(n ·d) computation cost to estimate fre-\nquency of all values.\nNumerical values of the approximate variances using\n(4) for all protocols are given in Table 2 and Figure 1 (n =\n10,000). Our analysis gives the following guidelines for\nchoosing protocols.\n• When d is small, more precisely, whend < 3eε +2,\nDE is the best among all approaches.\n• When d > 3eε + 2, and the communication cost\nΘ(d) is acceptable, one should use OUE. (OUE has\nthe same variance as OLH, but is easier to imple-\nment and faster because no hash functions is used.)\n• When d is so large that the communication cost\nΘ(d) is too large, we should use OLH. It offers\nthe same accuracy as OUE, but has communication\ncost O(logd) instead of O(d).\nDiscussion. In addition to the guidelines, we make the\nfollowing observations. Adding Laplacian noises to a\nhistogram is typically used in a setting with a trusted\ndata curator, who first computes the histogram from all\nusers’ data and then adds the noise. SHE applies it to\neach user’s data. Intuitively, this should perform poorly\nrelative to other protocols specifically designed for the\nlocal setting. However, SHE performs very similarly to\nBLH, which was specifically designed for the local set-\nting. In fact, when ε > 2.5, SHE performs better than\nBLH.\nWhile all protocols’ variances depend on ε, the rela-\ntionships are different. BLH is least sensitive to change\nin ε because binary hashing loses too much information.\nIndeed, while all other protocols have variance goes to\n0 when ε goes to infinity, BLH has variance goes to n.\nSHE is slightly more sensitive to change in ε. DE is\nmost sensitive to change in ε; however, when d is large,\nits variance is very high. OLH and OUE are able to better\nbenefit from an increase in ε, without suffering the poor\nperformance for small ε values.\nAnother interesting finding is that when d = 2, the\nvariance of DE is eε\n(eε −1)2 , which is exactly 1\n4 of that of\nUSENIX Association 26th USENIX Security Symposium    737\n\nDE SHE THE (θ = 1) SUE OUE BLH OLH\nCommunication Cost O(logd) O(d) O(d) O(d) O(d) O(logn) O(logn)\nVar[˜c(i)]/n d−2+eε\n(eε −1)2\n8\nε2\n2eε/2−1\n(eε/2−1)2\neε/2\n(eε/2−1)2\n4eε\n(eε −1)2\n(eε +1)2\n(eε −1)2\n4eε\n(eε −1)2\nTable 1: Comparison of communication cost and variances for different methods.\nDE (d = 2) DE (d = 32) DE (d = 210) SHE THE (θ = 1) SUE OUE BLH OLH\nε = 0.5 3.92 75.20 2432.40 32.00 19.44 15.92 15.67 16.67 15.67\nε = 1.0 0.92 11.08 347.07 8.00 5.46 3.92 3.68 4.68 3.68\nε = 2.0 0.18 0.92 25.22 2.00 1.50 0.92 0.72 1.72 0.72\nε = 4.0 0.02 0.03 0.37 0.50 0.34 0.18 0.08 1.08 0.08\nTable 2: Numerical values of Var [˜c(i)]/n for different methods.\n102\n103\n104\n105\n106\n107\n 0.5  1  1.5  2  2.5  3  3.5  4  4.5  5\nVar\nε\nDE(d=2)\nDE(d=4)\nDE(d=16)\nDE(d=128)\nDE(d=2048)\nOUE\n(a) Vary ε\n102\n103\n104\n105\n106\n107\n 0.5  1  1.5  2  2.5  3  3.5  4  4.5  5\nVar\nε\nDE\nSHE\nSUE\nOUE\nBLH\nOLH (b) Vary ε (fixing d = 210)\nFigure 1: Numerical values of Var[˜c(i)] for different methods.\nOUE and OLH, whose variances do not depend ond. In-\ntuitively, it is easier to transmit a piece of information\nwhen it is binary, i.e., d = 2. As d increases, one needs\nto “pay” for this increase in source entropy by having\nhigher variance. However, it seems that there is a cap on\nthe “price” one must pay no matter how large d is, i.e.,\nOLH’s variance does not depend on d and is always 4\ntimes that of DE with d = 2. There may exist a deeper\nreason for this rooted in information theory. Exploring\nthese questions is beyond the scope of this paper.\n6 Experimental Evaluation\nWe empirically evaluate these protocols on both syn-\nthetic and real-world datasets. All experiments are per-\nformed ten times and we plot the mean and standard de-\nviation.\n6.1 Verifying Correctness of Analysis\nThe conclusions we drew above are based on analyti-\ncal variances. We now show that our analytical results\nof variances match the empirically measured squared er-\nrors. For the empirical data, we issue queries using the\nprotocols and measure the average of the squared errors,\nnamely, 1\nd ∑i∈[d] [˜c(i)−n fi]2, where fi is the fraction of\nusers taking value i. We run queries for all i values and\nrepeat for ten times. We then plot the average and stan-\ndard deviation of the squared error. We use synthetic data\ngenerated by following the Zipf’s distribution (with dis-\ntribution parameter s = 1.1 and n = 10,000 users), simi-\nlar to experiments in [13].\nFigure 2 gives the empirical and analytical results for\nall methods. In Figures 2(a) and 2(b), we fix ε = 4\nand vary the domain size. For sufficiently large d (e.g.,\nd ≥ 26), the empirical results match very well with the\nanalytical results. When d < 26, the analytical variance\ntends to underestimate the variance, because in (4) we\nignore the fi terms. Standard deviation of the measured\nsquared error from different runs also decreases when the\ndomain size increases. In Figures 2(c) and 2(d), we fix\nthe domain size to d = 210 and vary the privacy budget.\nWe can see that the analytical results match the empirical\nresults for all ε values and all methods.\nIn practice, since the group size g of OLH can only be\n738    26th USENIX Security Symposium USENIX Association\n\n102\n103\n104\n105\n22 24 26 28 210 212 214 216 218\nVar\nd\nEmpirical DE\nEmpirical SUE\nEmpirical OUE\nAnalytical DE\nAnalytical SUE\nAnalytical OUE\n(a) Vary d (fixing ε = 4)\n102\n103\n104\n105\n22 24 26 28 210 212 214 216 218\nVar\nd\nEmpirical SHE\nEmpirical BLH\nEmpirical OLH\nAnalytical SHE\nAnalytical BLH\nAnalytical OLH (b) Vary d (fixing ε = 4)\n102\n103\n104\n105\n106\n107\n 0.5  1  1.5  2  2.5  3  3.5  4  4.5  5\nVar\nε\nEmpirical DE\nEmpirical SUE\nEmpirical OUE\nAnalytical DE\nAnalytical SUE\nAnalytical OUE\n(c) Vary ε (fixing d = 210)\n102\n103\n104\n105\n106\n107\n 0.5  1  1.5  2  2.5  3  3.5  4  4.5  5\nVar\nε\nEmpirical SHE\nEmpirical BLH\nEmpirical OLH\nAnalytical SHE\nAnalytical BLH\nAnalytical OLH (d) Vary ε (fixing d = 210)\nFigure 2: Comparing empirical and analytical variance.\nintegers, we round g = eε +1 to the nearest integer.\n6.2 Towards Real-world Estimation\nWe run OLH, BLH, together with RAPPOR, on real\ndatasets. The goal is to understand how does each pro-\ntocol perform in real world scenarios and how to inter-\npret the result. Note that RAPPOR does not fall into\nthe pure framework of LDP protocols so we cannot use\nTheorem 2 to obtain the variance analytically. Instead,\nwe run experiments to examine its performance empiri-\ncally. Following the setting of Erlingsson et al. [13], we\nuse a 128-bit Bloom filter, 2 hash functions and 8/16 co-\nhorts in RAPPOR. In order to vary ε, we tweak the f\nvalue. The instantaneous randomization process is omit-\nted. We implement RAPPOR in Python. The regression\npart, which RAPPOR introduces to handle the collisions\nin the Bloom filter, is implemented using Scikit-learn li-\nbrary [4].\nDatasets. We use the Kosarak dataset [2], which con-\ntains the click stream of a Hungarian news website.\nThere are around 8 million click events for 41 ,270 dif-\nferent pages. The goal is to estimate the popularity of\neach page, assuming all events are reported.\n6.2.1 Accuracy on Frequent Values\nOne goal of estimating a distribution is to find out the fre-\nquent values and accurately estimate them. We run dif-\nferent methods to estimate the distribution of the Kosarak\ndataset. After the estimation, we issue queries for the\n30 most frequent values in the original dataset. We then\ncalculate the average squared error of the 30 estimations\nproduced by different methods. Figure 3 shows the re-\nsult. We try RAPPOR with both 8 cohorts (RAP(8)) and\n16 cohorts (RAP(16)). It can be seen that when ε > 1,\nOLH starts to show its advantage. Moreover, variance\nof OLH decreases fastest among the four. Due to the\ninternal collision caused by Bloom filters, the accuracy\nof RAPPOR does not benefit from larger ε. We also per-\nform this experiment on different datasets, and the results\nare similar.\n6.2.2 Distinguish True Counts from Noise\nAlthough there are noises, infrequent values are still un-\nlikely to be estimated to be frequent. Statistically, the fre-\nquent estimates are more reliable, because the probabil-\nity it is generated from an infrequent value is quite low.\nHowever, for the infrequent estimates, we don’t know\nwhether it comes from an originally infrequent value or\nUSENIX Association 26th USENIX Security Symposium    739\n\n105\n106\n107\n108\n109\n1010\n 0.5  1  1.5  2  2.5  3  3.5  4  4.5  5\nVar\nε\nOLH\nBLH\nRAP(8)\nRAP(16)\nFigure 3: Average squared error, varying ε.\n 0\n 50\n 100\n 150\n 200\n 250\n 300\n 350\n 400\n 450\n 0.5  1  1.5  2  2.5  3  3.5  4  4.5  5\nTP\nε\nOLH\nBLH\nRAP(8)\nRAP(16)\nFigure 4: Number of true positives, varying ε, using\nsignificance threshold. The dashed line corresponds to\nthe average number of items identified.\na zero-count value. Therefore, after getting the estima-\ntion, we need to choose which estimate to use, and which\nto discard.\nSignificance Threshold. In [13], the authors propose\nto use the significance threshold. After the estimation,\nall estimations above the threshold are kept, and those\nbelow the threshold Ts are discarded.\nTs = Φ−1\n(\n1 − α\nd\n)√\nVar∗,\nwhere d is the domain size, Φ−1 is the inverse of the\ncumulative density function of standard normal distri-\nbution, and the term inside the square root is the vari-\nance of the protocol. Roughly speaking, the parame-\nter α controls the number of values that originally have\nlow frequencies but estimated to have frequencies above\nthe threshold (also known as false positives). We use\nα = 0.05 in our experiment.\nFor the values whose estimations are discarded, we\ndon’t know for sure whether they have low or zero fre-\nquencies. Thus, a common approach is to assign the re-\nmaining probability to each of them uniformly.\nRecall Var∗ is the term we are trying to minimize. So a\nprotocol with a smaller variance will have a lower thresh-\nold; thus more values can be detected reliably.\nNumber of Reliable Estimation. We run different pro-\ntocols using the significance threshold Ts on the Kosarak\ndataset. Note that Ts will change as ε changes. We define\na true (false) positive as a value that has frequency above\n(below) the threshold, and is estimated to have frequency\nabove the threshold. In Figure 4, we show the number of\ntrue positives versus ε. As ε increases, the number of\ntrue positives increases. When ε = 4, RAPPOR can out-\nput 75 true positives, BLH can only output 36 true posi-\ntives, but OLH can output nearly 200 true positives. We\nalso notice that the output sizes are similar for RAPPOR\nand OLH, which indicates that OLH gives out very few\nfalse positives compared to RAPPOR. The cohort size\ndoes not affect much in this setting.\n6.2.3 On Information Quality\nNow we test both the number of true positives and false\npositives, varying the threshold. We run OLH, BLH and\nRAPPOR on the Kosarak dataset.\nAs we can see in Figure 5(a), fixing a threshold, OLH\nand BLH performs similarly in identifying true positives,\nwhich is as expected, because frequent values are rare,\nand variance does not change much the probability it is\nidentified. RAPPOR performs slightly worse because of\nthe Bloom filter collision.\nAs for the false positives, as shown in Figure 5(b), dif-\nferent protocols perform quite differently in eliminating\nfalse positives. When fixing Ts to be 5 ,000, OLH pro-\nduces tens of false positives, but BLH will produce thou-\nsands of false positives. The reason behind this is that,\nfor the majority of infrequent values, their estimations\nare directly related to the variance of the protocol. A\nprotocol with a high variance means that more infrequent\nvalues will become frequent during estimation. As a re-\nsult, because of its smallest Var∗, OLH produces the least\nfalse positives while generating the most true positives.\n7 Related Work\nThe notion of differential privacy and the technique of\nadding noises sampled from the Laplace distribution\nwere introduced in [11]. Many algorithms for the central-\nized setting have been proposed. See [12] for a theoreti-\ncal treatment of these techniques, and [19] for a treatment\nfrom a more practical perspective. It appears that only\nalgorithms for the LDP settings have seen real world de-\nployment. Google deployed RAPPOR [13] in Chrome,\nand Apple [1] also uses similar methods to help with pre-\ndictions of spelling and other things.\nState of the art protocols for frequency estimation un-\nder LDP are RAPPOR by Erlingsson et al. [13] and Ran-\ndom Matrix Projection (BLH) by Bassily and Smith [6],\n740    26th USENIX Security Symposium USENIX Association\n\n 0\n 20\n 40\n 60\n 80\n 100\n 120\n 140\n 160\n 5000  10000  15000  20000\nTP\nThreshold\nOLH\nBLH\nRAP(8)\nRAP(16)\n(a) Number of True Positives\n100\n101\n102\n103\n104\n 5000  10000  15000  20000\nFP\nThreshold\nOLH\nBLH\nRAP(8)\nRAP(16) (b) Number of False Positives\nFigure 5: Results on Kosarak dataset. The y axes are the number of identified hash values that is true/false positive.\nThe x axes are the threshold. We assume ε = 4.\nwhich we have presented in Section 2 and compared with\nin detail in the paper. These protocols use ideas from\nearlier work [20, 9]. Our proposed Optimized Unary\nEncoding (OUE) protocol builds upon the Basic RAP-\nPOR protocol in [13]; and our proposed Optimized Lo-\ncal Hashing (OLH) protocol is inspired by BLH in [6].\nWang et al. [23] uses both generalized random response\n(Section 4.1) and Basic RAPPOR for learning weighted\nhistogram. Some researchers use existing frequency esti-\nmation protocols as primitives to solve other problems in\nLDP setting. For example, Chen et al. [8] uses BLH [6]\nto learn location information about users. Qin et al. [22]\nuse RAPPOR [13] and BLH [6] to estimate frequent\nitems where each user has a set of items to report. These\ncan benefit from the introduction of OUE and OLH in\nthis paper.\nThere are other interesting problems in the LDP set-\nting beyond frequency estimation. In this paper we do\nnot study them. One problem is to identify frequent val-\nues when the domain of possible input values is very\nlarge or even unbounded, so that one cannot simply ob-\ntain estimations for all values to identify which ones are\nfrequent. This problem is studied in [17, 6, 16]. Another\nproblem is estimating frequencies of itemsets [14, 15].\nNguyˆen et al. [21] studied how to report numerical an-\nswers (e.g., time of usage, battery volume) under LDP.\nWhen these protocols use frequency estimation as a\nbuilding block (such as in [16]), they can directly ben-\nefit from results in this paper. Applying insights gained\nin our paper to better solve these problems is interesting\nfuture work.\nKairouz et al. [18] study the problem of finding the\noptimal LDP protocol for two goals: (1) hypothesis test-\ning, i.e., telling whether the users’ inputs are drawn from\ndistribution P0 or P1, and (2) maximize mutual informa-\ntion between input and output. We note that these goals\nare different from ours. Hypothesis testing does not re-\nflect dependency on d. Mutual information considers\nonly a single user’s encoding, and not aggregation ac-\ncuracy. For example, both global and local hashing have\nexactly the same mutual information characteristics, but\nthey have very different accuracy for frequency estima-\ntion, because of collisions in global hashing. Neverthe-\nless, it is found that for very large ε’s, Direct Encoding\nis optimal, and for very small ε’s, BLH is optimal. This\nis consistent with our findings. However, analysis in [18]\ndid not lead to generalization and optimization of binary\nlocal hashing, nor does it provide concrete suggestion on\nwhich method to use for a given ε and d value.\n8 Discussion\nOn answering multiple questions. In the setting of tra-\nditional DP, the privacy budget is split when answering\nmultiple queries. In the local setting, previous work fol-\nlow this tradition and let the users split privacy budget\nevenly and report on multiple questions. Instead, we sug-\ngest partitioning the users randomly into groups, and let-\nting each group of users answer a separate question. Now\nwe compare the utilities by these approaches.\nSuppose there are Q ≥ 2 questions. We calculate vari-\nances on one question. Since there are different number\nof users in the two cases ( n versus n/Q), we normalize\nthe estimations into the range from 0 to 1. In OLH, the\nvariance is σ2 = Var∗[˜cOLH(i)/n] = 4eε\n(eε −1)2·n .\nWhen partitioning the users, n/Q users answer one\nquestion, rendering σ2\n1 = 4Qeε\n(eε −1)2·n ; when privacy bud-\nget is split, ε/Q is used for one question, we have σ2\n2 =\n4eε/Q\n(eε/Q−1)\n2·n\n. We want to show σ2\n1 < σ2\n2 :\nσ2\n2 −σ2\n1\nUSENIX Association 26th USENIX Security Symposium    741\n\n=4\nn\n(\neε/Q\n(\neε/Q −1\n)2 − Qeε\n(eε −1)2\n)\n= 4eε/Q\nn\n(\neε/Q −1\n)2 (eε −1)2\n·\n[\n(eε −1)2 −Qeε−ε/Q\n(\neε/Q −1\n)2]\nThe first term is always greater than zero sinceε > 0. For\nthe second term, we define eε/Q = z, and write it as:\n(zQ −1)2 −QzQ−1(z −1)2\n=(z −1)2 ·\n[\n(zQ−1 +zQ−2 +... +1)2 −QzQ−1]\n> 0\nTherefore, σ2\n1 is always smaller than σ2\n2 . Thus utility\nof partitioning users is better than splitting privacy bud-\nget.\nLimitations. The current work only considers the frame-\nwork of pure LDP protocols. It is not known whether a\nprotocol that is not pure will produce more accurate re-\nsult or not. Moreover, current protocols can only handle\nthe case where the domain is limited, or a dictionary is\navailable. Other techniques are needed when the domain\nsize is very big.\n9 Conclusion\nIn this paper, we study frequency estimation in the Local\nDifferential Privacy (LDP) setting. We have introduced a\nframework of pure LDP protocols together with a simple\nand generic aggregation and decoding technique. This\nframework enables us to analyze, compare, generalize,\nand optimize different protocols, significantly improving\nour understanding of LDP protocols. More concretely,\nwe have introduced the Optimized Local Hashing (OLH)\nprotocol, which has much better accuracy than previous\nfrequency estimation protocols satisfying LDP. We pro-\nvide a guideline as to which protocol to choose in differ-\nent scenarios. Finally we demonstrate the advantage of\nthe OLH in both synthetic and real-world datasets.\n10 Acknowledgment\nThis paper is based on work supported by the United\nStates National Science Foundation under Grant No.\n1640374.\nReferences\n[1] Apples differential privacy is about col-\nlecting your databut not your data.\nhttps://www.wired.com/2016/06/\napples-differential-privacy-collecting-data/ .\n[2] Kosarak. http://fimi.ua.ac.be/data/.\n[3] Rappor online description. http:\n//www.chromium.org/developers/\ndesign-documents/rappor.\n[4] Scikit-learn. http://scikit-learn.org/.\n[5] Source code of rappor in chromium. https://cs.\nchromium.org/chromium/src/components/\nrappor/public/rappor_parameters.h.\n[6] B ASSILY, R., AND SMITH , A. Local, private, ef-\nficient protocols for succinct histograms. In Pro-\nceedings of the Forty-Seventh Annual ACM on Sym-\nposium on Theory of Computing (2015), ACM,\npp. 127–135.\n[7] B LOOM , B. H. Space/time trade-offs in hash cod-\ning with allowable errors. Commun. ACM 13 , 7\n(July 1970), 422–426.\n[8] C HEN , R., L I, H., Q IN, A. K., K A-\nSIVISWANATHAN , S. P., AND JIN, H. Private\nspatial data aggregation in the local setting. In\n32nd IEEE International Conference on Data\nEngineering, ICDE 2016, Helsinki, Finland, May\n16-20, 2016 (2016), pp. 289–300.\n[9] D UCHI , J. C., J ORDAN , M. I., AND WAIN -\nWRIGHT , M. J. Local privacy and statistical mini-\nmax rates. In FOCS (2013), pp. 429–438.\n[10] D WORK , C. Differential privacy. In ICALP (2006),\npp. 1–12.\n[11] D WORK , C., M CSHERRY, F., N ISSIM , K., AND\nSMITH , A. Calibrating noise to sensitivity in pri-\nvate data analysis. In TCC (2006), pp. 265–284.\n[12] D WORK , C., AND ROTH , A. The algorithmic\nfoundations of differential privacy. Foundations\nand Trends in Theoretical Computer Science 9 , 34\n(2014), 211–407.\n[13] E RLINGSSON , ´U., P IHUR , V., AND KOROLOVA ,\nA. Rappor: Randomized aggregatable privacy-\npreserving ordinal response. In Proceedings of the\n2014 ACM SIGSAC conference on computer and\ncommunications security (2014), ACM, pp. 1054–\n1067.\n[14] E VFIMIEVSKI , A., G EHRKE , J., AND SRIKANT ,\nR. Limiting privacy breaches in privacy preserving\ndata mining. In PODS (2003), pp. 211–222.\n[15] E VFIMIEVSKI , A., S RIKANT , R., A GRAWAL , R.,\nAND GEHRKE , J. Privacy preserving mining of as-\nsociation rules. In KDD (2002), pp. 217–228.\n742    26th USENIX Security Symposium USENIX Association\n\n[16] F ANTI , G., P IHUR , V., AND ERLINGSSON , ´U.\nBuilding a rappor with the unknown: Privacy-\npreserving learning of associations and data dictio-\nnaries. Proceedings on Privacy Enhancing Tech-\nnologies (PoPETS) issue 3, 2016 (2016).\n[17] H SU, J., K HANNA , S., AND ROTH , A. Dis-\ntributed private heavy hitters. In International Col-\nloquium on Automata, Languages, and Program-\nming (2012), Springer, pp. 461–472.\n[18] K AIROUZ , P., O H, S., AND VISWANATH , P. Ex-\ntremal mechanisms for local differential privacy. In\nAdvances in neural information processing systems\n(2014), pp. 2879–2887.\n[19] L I, N., L YU, M., S U, D., AND YANG , W. Differ-\nential Privacy: From Theory to Practice . Synthe-\nsis Lectures on Information Security, Privacy, and\nTrust. Morgan Claypool, 2016.\n[20] M ISHRA , N., AND SANDLER , M. Privacy via\npseudorandom sketches. In Proceedings of the\ntwenty-fifth ACM SIGMOD-SIGACT-SIGART sym-\nposium on Principles of database systems (2006),\nACM, pp. 143–152.\n[21] N GUY ˆEN, T. T., XIAO , X., YANG , Y., HUI, S. C.,\nSHIN , H., AND SHIN , J. Collecting and analyzing\ndata from smart device users with local differential\nprivacy. arXiv preprint arXiv:1606.05053 (2016).\n[22] Q IN, Z., Y ANG , Y., Y U, T., K HALIL , I., X IAO ,\nX., AND REN, K. Heavy hitter estimation over set-\nvalued data with local differential privacy. In CCS\n(2016).\n[23] W ANG , S., H UANG , L., W ANG , P., D ENG , H.,\nXU, H., AND YANG , W. Private weighted his-\ntogram aggregation in crowdsourcing. In Interna-\ntional Conference on Wireless Algorithms, Systems,\nand Applications (2016), Springer, pp. 250–261.\n[24] W ARNER , S. L. Randomized response: A sur-\nvey technique for eliminating evasive answer bias.\nJournal of the American Statistical Association 60,\n309 (1965), 63–69.\nA Additional Evaluation\nThis section provides additional experimental evaluation\nresults. We first try to measure average squared variance\non other datasets. Although RAPPOR did not specify a\nparticular optimal setting, we vary the number of cohorts\nand find differences. In the end, we evaluate different\nmethods on the Rockyou dataset.\nA.1 Effect of Cohort Size\nIn [13], the authors did not identify the best cohort size\nto use. Intuitively, if there are too few cohorts, many val-\nues will be hashed to be the same in the Bloom filter,\nmaking it difficult to distinguish these values. If there\nare more cohorts, each cohort cannot convey enough use-\nful information. Here we try to test what cohort size we\nshould use. We generate 10 million values following the\nZipf’s distribution (with parameter 1.5), but only use the\nfirst 128 most frequent values because of memory limita-\ntion caused by regression part of RAPPOR. We then run\nRAPPOR using 8, 16, 32, and 64, and 128 cohorts. We\nmeasure the average squared errors of queries about the\ntop 10 values, and the results are shown in Figure 7. As\nwe can see, more cohorts does not necessarily help lower\nthe squared error because the reduced probability of col-\nlision within each cohort. But it also has the disadvan-\ntage that each cohort may have insufficient information.\nIt can be seen OLH still performs best.\nA.2 Performance on Synthetic Datasets\nIn Figure 6, we test performance of different methods on\nsynthetic datasets. We generate 10 million points follow-\ning a normal distribution (rounded to integers, with mean\n500 and standard deviation 10) and a Zipf’s distribution\n(with parameter 1.5). The values range from 0 to 1000.\nWe then test the average squared errors on the most fre-\nquent 100 values. It can be seen that different methods\nperform similarly in different distributions. RAPPOR us-\ning 16 cohorts performs better than BLH. This is be-\ncause when the number of cohort is enough, each user in\na sense has his own hash functions. This can be viewed\nas a kind of local hashing function. When we only test\nthe top 10 values instead of top 50, RAP(16) and BLH\nperform similarly. Note that OLH performs best among\nall distributions.\nA.3 Performance on Rockyou Dataset\nWe run experiments on theRockyou dataset, which con-\ntains 21 million users’ password in plaintext. We first\nhash the plaintext into 20 bits, and use OLH, BLH, and\nBasic RAPPOR (also known as SUE in our framework)\nto test all hashed values. It can be seen that OLH per-\nforms best in all settings, and basic RAPPOR outper-\nforms BLH consistently. When ε = 4, and threshold is\n6000, OLH can recover around 50 true frequent hashes\nand 10 of false positives, which is 4 and 2 magnitudes\nsmaller than BLH and basic RAPPOR, respectively. The\nadvantage is not significant when ε is small, since the\nvariance difference is small.\nUSENIX Association 26th USENIX Security Symposium    743\n\n105\n106\n107\n108\n109\n 0.5  1  1.5  2  2.5  3  3.5  4  4.5  5\nVar\nε\nOLH\nBLH\nRAP(8)\nRAP(16)\n(a) Zipf’s Top 100 Values\n105\n106\n107\n108\n109\n 0.5  1  1.5  2  2.5  3  3.5  4  4.5  5\nVar\nε\nOLH\nBLH\nRAP(8)\nRAP(16) (b) Normal Top 100 Values\n105\n106\n107\n108\n109\n 0.5  1  1.5  2  2.5  3  3.5  4  4.5  5\nVar\nε\nOLH\nBLH\nRAP(8)\nRAP(16)\n(c) Zipf’s Top 50 Values\n105\n106\n107\n108\n109\n 0.5  1  1.5  2  2.5  3  3.5  4  4.5  5\nVar\nε\nOLH\nBLH\nRAP(8)\nRAP(16) (d) Zipf’s Top 10 Values\nFigure 6: Average squared errors on estimating a distribution of 10 million points. RAPPOR is used with 128-bit\nlong Bloom filter and 2 hash functions.\n105\n106\n107\n108\n109\n 0.5  1  1.5  2  2.5  3  3.5  4  4.5  5\nVar\nε\nRAP(8)\nRAP(16)\nRAP(32)\nRAP(64)\nRAP(128)\nOLH\nFigure 7: Average squared error on estimating a normal\ndistribution of 1 million points. RAPPOR is used with\n128-bit long Bloom filter and 2 hash functions.\n744    26th USENIX Security Symposium USENIX Association\n\n 30\n 40\n 50\n 60\n 70\n 80\n 5000  5500  6000  6500\nTP\nThreshold\nOLH BLH BasicRAP\n(a) Number of True Positives ε = 4\n100\n101\n102\n103\n104\n105\n106\n 5000  5500  6000  6500\nFP\nThreshold\nOLH BLH BasicRAP (b) Number of False Positives ε = 4\n 4\n 5\n 6\n 7\n 8\n 9\n 15000  20000  25000\nTP\nThreshold\nOLH BLH BasicRAP\n(c) Number of True Positives ε = 2\n100\n101\n102\n103\n104\n105\n 15000  20000  25000\nFP\nThreshold\nOLH BLH BasicRAP (d) Number of False Positives ε = 2\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n 20000  30000  40000  50000\nTP\nThreshold\nOLH BLH BasicRAP\n(e) Number of True Positives ε = 1\n100\n101\n102\n103\n104\n105\n 20000  30000  40000  50000\nFP\nThreshold\nOLH BLH BasicRAP (f) Number of False Positives ε = 1\nFigure 8: Results on Rockyou dataset for ε = 4,2 and 1. The y axes are the number of identified hash values that is\ntrue/false positive. The x axes are the threshold.\nUSENIX Association 26th USENIX Security Symposium    745\n\n"
}