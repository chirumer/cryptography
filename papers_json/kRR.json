{
  "source_url": "/mnt/data/kRR.pdf",
  "metadata": {
    "title": "Discrete Distribution Estimation under Local Privacy",
    "authors": [
      {
        "name": "Peter Kairouz",
        "email": "KAIROUZ2@ILLINOIS.EDU",
        "affiliations": [
          "Google, 1600 Amphitheatre Parkway, Mountain View, CA 94043",
          "University of Illinois, Urbana-Champaign, 1308 W Main St, Urbana, IL 61801"
        ]
      },
      {
        "name": "Keith Bonawitz",
        "email": "BONAWITZ@GOOGLE.COM",
        "affiliations": ["Google, 1600 Amphitheatre Parkway, Mountain View, CA 94043"]
      },
      {
        "name": "Daniel Ramage",
        "email": "DRAMAGE@GOOGLE.COM",
        "affiliations": ["Google, 1600 Amphitheatre Parkway, Mountain View, CA 94043"]
      }
    ],
    "venue": "Proceedings of the 33rd International Conference on Machine Learning (ICML 2016), JMLR W&CP vol. 48",
    "arxiv": "arXiv:1602.07387v3 [stat.ML] (15 Jun 2016)",
    "pages": 27,
    "keywords": [
      "local differential privacy",
      "distribution estimation",
      "randomized response",
      "k-ary randomized response (k-RR)",
      "RAPPOR",
      "hashed cohorts",
      "open alphabets"
    ]
  },
  "abstract": "The paper studies discrete distribution estimation under local differential privacy (LDP). It introduces hashed k-ary Randomized Response (k-RR) for open alphabets (O-RR), shows via theory and large-scale simulations when k-RR or RAPPOR are order-optimal, and provides decoding strategies (notably simplex projection) that improve utility across privacy regimes.",
  "main_contributions": [
    "For binary alphabets, Warner‚Äôs randomized response (W-RR) is proven globally optimal for all losses and all Œµ (Theorem 2).",
    "For k-ary alphabets, k-RAPPOR is order-optimal in the high-privacy regime; k-RR is order-optimal in the low-privacy regime; each is strictly sub-optimal in the other‚Äôs regime (Section 4.1‚Äì4.3).",
    "Projected (simplex) decoding outperforms ML and truncation/renormalization for skewed distributions across privacy levels and sample sizes (Section 4.4).",
    "For open alphabets, O-RR (k-RR with hashing and cohorts) matches or exceeds O-RAPPOR utility across a wide privacy range; Bloom filters provide no benefit for distribution estimation (Section 5.1‚Äì5.3).",
    "For closed alphabets, using minimal perfect hashing (permutations) with O-RR significantly improves utility‚Äîmeeting or exceeding k-RR and RAPPOR in both high and low privacy regimes (Section 5.4)."
  ],
  "notation_and_setup": {
    "private_source": "X over finite alphabet ùí≥={x1,...,xk}",
    "mechanism": "Family of conditional distributions Q(y|x) represented as a k√ó‚Ñì row-stochastic matrix mapping X‚ÜíY",
    "local_DP": "Q(E|x) ‚â§ e^Œµ Q(E|x') for all x,x' and measurable E‚äÇùí¥ (Œµ‚â•0)",
    "task": "Estimate categorical distribution p‚ààŒî^{k-1} from privatized samples Y^n with Yi ~ pQ",
    "risk": "Minimax risk r_{‚Ñì,Œµ,k,n} = inf_{Q‚ààD_Œµ} inf_{pÃÇ} sup_{p} ùîº[‚Ñì(p,pÃÇ(Y^n))]"
  },
  "core_results": {
    "Proposition_1_high_privacy_bounds": {
      "statement": "For Œµ‚àà[0,1], there exist universal constants 0< c_l ‚â§ c_u < 5 such that r_{‚Ñì2^2,Œµ,k,n} and r_{‚Ñì1,Œµ,k,n} scale as O(k/(nŒµ^2)) and O(k/‚àö(nŒµ^2)) respectively.",
      "implication": "Effective sample size drops from n to ‚âà nŒµ^2/k in high privacy.",
      "section_pages": "Section 2.2; page ~3",
      "notes": "Formal inequalities given for ‚Ñì2^2 and ‚Ñì1 losses.",
      "refs": ["Duchi et al. 2013b"]
    },
    "Theorem_2_W_RR_optimal": {
      "mechanism": "W-RR with matrix Q_WRR = (1/(e^Œµ+1)) [[e^Œµ, 1],[1, e^Œµ]]",
      "statement": "For all binary p, all losses ‚Ñì, all Œµ‚â•0, W‚ÄëRR minimizes minimax risk.",
      "proof_idea": "W‚ÄëRR dominates other LDP mechanisms via a stochastic post-processing (data processing inequality).",
      "section_pages": "Section 3; pages ~3‚Äì4"
    },
    "k_RR_definition_and_estimators": {
      "Q_KRR": "Q(y|x) = e^Œµ/(k‚àí1+e^Œµ) if y=x; 1/(k‚àí1+e^Œµ) if y‚â†x",
      "output_mixture": "m = ((e^Œµ‚àí1)/(e^Œµ + k ‚àí 1)) p + (1/(e^Œµ + k ‚àí 1))¬∑1",
      "empirical_estimator": "pÃÇ = ((e^Œµ + k ‚àí 1)/(e^Œµ ‚àí 1)) mÃÇ ‚àí (1/(e^Œµ ‚àí 1))¬∑1",
      "expected_errors": {
        "L2": "ùîº||pÃÇ‚àíp||_2^2 = (1 ‚àí ‚àë p_i^2)/n + ((k‚àí1)/n)¬∑[k + 2(e^Œµ‚àí1)]/(e^Œµ‚àí1)^2",
        "L1_asympt": "‚âà Œ£_i sqrt( 2((e^Œµ‚àí1)p_i + 1)((e^Œµ‚àí1)(1 ‚àí p_i) + k ‚àí 1) / (œÄ n (e^Œµ‚àí1)^2) )"
      },
      "decoder_notes": "pÃÇ may leave simplex; best practice is projection onto simplex (Algorithm of Wang & Carreira‚ÄëPerpi√±√°n 2013).",
      "section_pages": "Section 4.1; pages ~4‚Äì5"
    },
    "k_RAPPOR_definition_and_estimators": {
      "embedding": "Map symbol i to standard basis e_i ‚àà {0,1}^k; then flip each bit independently",
      "bit_flip_probability": "P(Y^{(j)} = XÃÉ^{(j)}) = e^{Œµ/2}/(1+e^{Œµ/2}); P(flip)=1/(1+e^{Œµ/2})",
      "marginal": "P(Y^{(j)}=1) = ((e^{Œµ/2} ‚àí 1)/(e^{Œµ/2} + 1)) p_j + 1/(e^{Œµ/2} + 1)",
      "empirical_estimator": "pÃÇ_j = ((e^{Œµ/2}+1)/(e^{Œµ/2}‚àí1))¬∑(T_j/n) ‚àí 1/(e^{Œµ/2}‚àí1)",
      "expected_errors": {
        "L2": "ùîº||pÃÇ‚àíp||_2^2 = (1 ‚àí ‚àë p_i^2)/n + (k e^{Œµ/2}) / ( n (e^{Œµ/2} ‚àí 1)^2 )",
        "L1_asympt": "‚âà Œ£_i sqrt( 2((e^{Œµ/2}‚àí1)p_i + 1)((e^{Œµ/2}‚àí1)(1 ‚àí p_i) + 1) / (œÄ n (e^{Œµ/2} ‚àí 1)^2) )"
      },
      "section_pages": "Section 4.2; pages ~5‚Äì6"
    },
    "regime_comparison_and_order_optimality": {
      "k_RR": "Not optimal for small Œµ; becomes order‚Äëoptimal when Œµ‚âàln k (effective n ‚âà n/4).",
      "k_RAPPOR": "Order‚Äëoptimal for high privacy (Œµ small) but strictly sub‚Äëoptimal for moderate‚Äëto‚Äëlow privacy (e.g., for Œµ‚âàln k, effective n drops to n/‚àök).",
      "formal_comparison": "For ML under ‚Ñì2, ùîº||pÃÇ_KRR‚àíp||_2^2 ‚â§ ùîº||pÃÇ_RAPPOR‚àíp||_2^2 when Œµ ‚â• ln(k/2) (main text), with a slightly stronger bound Œµ ‚â• ln k shown in the supplementary proof (both assert k‚ÄëRR wins in that regime).",
      "section_pages": "Section 4.3; page ~5"
    }
  },
  "algorithms_and_decoding": {
    "decoders_considered": [
      "Empirical (direct inverter)",
      "Normalized/truncated (clip negatives, renormalize)",
      "Projected (simplex projection; best for skewed distributions)",
      "Maximum likelihood (specific forms for k-RR and k-RAPPOR)"
    ],
    "ML_for_k_RR": {
      "solution": "pÃÇ_i = max(0, T_i/Œª ‚àí 1/(e^Œµ‚àí1)) with Œª chosen so Œ£_i pÃÇ_i = 1",
      "complexity": "O(k log k) using water-filling (Boyd & Vandenberghe)",
      "where": "Supplement F.1‚ÄìF.2"
    },
    "ML_for_k_RAPPOR": {
      "objective": "maximize Œ£_j (n‚àíT_j) log((1‚àíŒ¥) ‚àí (1‚àí2Œ¥)p_j) + T_j log((1‚àí2Œ¥)p_j + Œ¥), Œ¥=1/(e^{Œµ/2}+1)",
      "note": "Convex program in k variables (Supplement F.3‚ÄìF.4)"
    },
    "decoder_choice_finding": "Projected (simplex) decoding consistently best for skewed distributions; normalized best for flat Dirichlet (Section 4.4)."
  },
  "open_alphabets_O_RR_and_O_RAPPOR": {
    "O_RR_encoding": {
      "cohorts": "Each user assigned cohort c‚àà{1,...,C} uniformly",
      "hash": "C independent hash functions HASH_c(¬∑) mod k project S‚Üí{0,...,k‚àí1}",
      "mechanism": "Q_ORR(y,c|s) = [1/(C(e^Œµ+k‚àí1))]¬∑(e^Œµ if HASH_c^{(k)}(s)=y; else 1)"
    },
    "O_RR_decoding": {
      "linear_system": "Interpret mechanism as kC√ó|S| matrix Q_ORR = (1/C)¬∑(1/(e^Œµ+k‚àí1))¬∑(I + (e^Œµ‚àí1)H) where H(y,c|s)=1{HASH_c^{(k)}(s)=y}",
      "empirical_estimator": "pÃÇ_ORR H = (1/(e^Œµ‚àí1))¬∑(C(e^Œµ+k‚àí1) mÃÇ ‚àí 1)",
      "postproc": "Project pÃÇ to simplex"
    },
    "O_RAPPOR": {
      "embedding": "Use h-hash Bloom filter per cohort (C cohorts) before applying k‚ÄëRAPPOR",
      "finding": "For distribution estimation, optimal h‚âà1; Bloom filters bring no benefit beyond simple hashing",
      "decoder": "Least‚Äësquares (Lasso step and Bonferroni filtering not used here)"
    },
    "conditions_for_accurate_decoding_under_k_RR": {
      "distinguishability": "Probability a string is distinguishable among S strings is ((k^C‚àí1)/k^C)^{S‚àí1}",
      "recoverable_mass": "Expected recoverable probability mass ‚â• P_t requires k^C ‚â• (1 ‚àí P_t^{1/(S‚àí1)})^{-1}",
      "well_constrained_system": "Need k^C ‚â• S equations to avoid under‚Äëconstrained linear system",
      "variance_condition": "n must be large enough for small variance in pÃÇ (qualitative guidance)"
    },
    "empirical_findings": [
      "O‚ÄëRR matches O‚ÄëRAPPOR at very low and high privacy and exceeds it at midrange Œµ.",
      "For O‚ÄëRR: optimal k grows with Œµ; increasing C improves low‚Äëto‚Äëmid privacy; C=1 underperforms.",
      "For O‚ÄëRAPPOR: performance improves with larger k (approaching asymptote near k=4096); C‚â•2 suffices; h=1 is optimal."
    ]
  },
  "simulation_setup_and_results": {
    "distributions": [
      "Binomial with p ‚àà {0.1,0.2,0.3,0.4,0.5}",
      "Zipf with parameter ‚àà {1,2,3,4,5}",
      "Multinomial from symmetric Dirichlet(1‚Éó)",
      "Geometric with mean k/5 (k‚Äëary) or |S|/5 (open/closed)"
    ],
    "evaluation_metric": "‚Ñì1 distance between decoded distribution and ground‚Äëtruth sample distribution",
    "decoding_takeaways": [
      "Projected decoder best for skewed distributions across k and Œµ; normalized best for flat Dirichlet.",
      "k‚ÄëRAPPOR beats k‚ÄëRR when k is large and Œµ small; k‚ÄëRR slightly better whenever k < e^Œµ (empirical ‚Ñì1 complementing theory in ‚Ñì2).",
      "As n increases, k‚ÄëRR‚Äôs advantage in low privacy shrinks."
    ],
    "parameter_search": "Grid‚Äësearch over k ‚àà [2,4,8,...,4096], C ‚àà [1,2,4,...,1024], h ‚àà [1,2,4,8,16] (extended up to k=16384, n up to 1e8 in supplementary).",
    "n_values": ["100", "3e4", "1e6", "1e8 (supplementary)"]
  },
  "figures": [
    {
      "figure": "Figure 1",
      "page": 7,
      "topic": "Projected decoder improvement for k‚ÄëRR and k‚ÄëRAPPOR (‚Ñì1)",
      "takeaway": "Simplex projection outperforms ML/normalized decoders across k, Œµ for skewed data."
    },
    {
      "figure": "Figure 2",
      "page": 7,
      "topic": "Best k‚ÄëRR vs best k‚ÄëRAPPOR decoders (‚Ñì1) for small (100) and large (30k) n",
      "takeaway": "k‚ÄëRAPPOR wins for large k & low Œµ; k‚ÄëRR wins whenever k < e^Œµ."
    },
    {
      "figure": "Figure 3 (a,b)",
      "page": 7,
      "topic": "‚Ñì1 loss of O‚ÄëRR vs O‚ÄëRAPPOR (open vs closed alphabets), n=10^6",
      "takeaway": "O‚ÄëRR ‚â• O‚ÄëRAPPOR in midrange; benefits strongly in closed alphabets with perfect hashing."
    },
    {
      "figure": "Figure 4",
      "page": 18,
      "topic": "Geometric input distribution used in experiments"
    },
    {
      "figure": "Figures 5‚Äì6",
      "pages": "18‚Äì19",
      "topic": "‚Ñì2 analogs of projected‚Äëdecoder improvements and k‚ÄëRR vs k‚ÄëRAPPOR",
      "takeaway": "Patterns mirror ‚Ñì1 results."
    },
    {
      "figure": "Figures 7‚Äì16",
      "pages": "20‚Äì27",
      "topic": "Open/closed alphabet losses vs Œµ; parameter sweeps over k, C, h; privacy attainable vs target ‚Ñì1 at n",
      "takeaway": "C‚â•2 sufficient for O‚ÄëRAPPOR; h=1; O‚ÄëRR benefits from larger C at mid‚Äëprivacy; privacy‚Äëutility trade‚Äëoffs quantified for S=256 and 4096; results shown for n=10^6 and 10^8."
    }
  ],
  "equations_by_label": [
    {"id": "(1)", "text": "Q(E|x) ‚â§ e^{Œµ} Q(E|x')  for all x,x', E‚äÇùí¥  (Local DP)"},
    {"id": "(2)", "text": "r_{‚Ñì,Œµ,k,n} = inf_{Q‚ààD_Œµ} inf_{pÃÇ} sup_{p} ùîº[‚Ñì(p,pÃÇ)]"},
    {"id": "(3)", "text": "Q_WRR = (1/(e^{Œµ}+1)) [[e^{Œµ}, 1], [1, e^{Œµ}]]"},
    {"id": "(4)", "text": "Q_KRR(y|x) = e^{Œµ}/(k‚àí1+e^{Œµ}) if y=x; 1/(k‚àí1+e^{Œµ}) otherwise"},
    {"id": "(5)", "text": "m = ((e^{Œµ}‚àí1)/(e^{Œµ}+k‚àí1)) p + (1/(e^{Œµ}+k‚àí1))¬∑1"},
    {"id": "(6)", "text": "pÃÇ = ((e^{Œµ}+k‚àí1)/(e^{Œµ}‚àí1)) mÃÇ ‚àí (1/(e^{Œµ}‚àí1))¬∑1"},
    {"id": "(7)", "text": "Q_KRR^{-1}(y|x)= (e^{Œµ}+k‚àí2)/(e^{Œµ}‚àí1) if y=x;  ‚àí1/(e^{Œµ}‚àí1) otherwise"},
    {"id": "(10)", "text": "P(Y^{(j)}=1) = ((e^{Œµ/2}‚àí1)/(e^{Œµ/2}+1)) p_j + 1/(e^{Œµ/2}+1)"},
    {"id": "(11)", "text": "pÃÇ_j = ((e^{Œµ/2}+1)/(e^{Œµ/2}‚àí1))¬∑(T_j/n) ‚àí 1/(e^{Œµ/2}‚àí1)"},
    {"id": "(14)", "text": "For Œµ ‚â• ln(k/2): ùîº||pÃÇ_KRR‚àíp||_2^2 ‚â§ ùîº||pÃÇ_RAPPOR‚àíp||_2^2 (ML)"},
    {"id": "(15)", "text": "Q_ORR(y,c|s) = 1/[C(e^{Œµ}+k‚àí1)]¬∑(e^{Œµ} if HASH_c^{(k)}(s)=y; else 1)"},
    {"id": "(16)", "text": "Q_ORR = (1/C)¬∑(1/(e^{Œµ}+k‚àí1))¬∑(I + (e^{Œµ}‚àí1)H)"},
    {"id": "(17)", "text": "H(y,c|s) = 1{HASH_c^{(k)}(s)=y}"},
    {"id": "(18)", "text": "pÃÇ_ORR H = (1/(e^{Œµ}‚àí1))¬∑(C(e^{Œµ}+k‚àí1) mÃÇ ‚àí 1)"},
    {"id": "(28‚Äì29)", "text": "ML for k‚ÄëRR: pÃÇ_i = max(0, T_i/Œª ‚àí 1/(e^{Œµ}‚àí1)), with Œ£_i pÃÇ_i = 1; Œª via water‚Äëfilling"},
    {"id": "(30‚Äì32)", "text": "Derivation for ML under k‚ÄëRR: show Œ£_j Q_KRR(Y_i|X=j) p_j = ((e^{Œµ}‚àí1) p_{Y_i} + 1)/(e^{Œµ}+k‚àí1)"},
    {"id": "(34)", "text": "Expected number of distinguishable strings among S: S¬∑((k^C ‚àí 1)/k^C)^{S‚àí1}; probability a given string is distinguishable: ((k^C ‚àí 1)/k^C)^{S‚àí1}"}
  ],
  "practical_guidelines_from_paper": [
    "Use projected (simplex) decoding for skewed data.",
    "Choose mechanism by privacy regime: k‚ÄëRAPPOR for high privacy; k‚ÄëRR (or O‚ÄëRR) for moderate‚Äëto‚Äëlow privacy.",
    "For open alphabets, use cohorts (C‚â•2) and hashing; Bloom filters (h>1) are unnecessary for distribution estimation.",
    "For closed alphabets, prefer O‚ÄëRR with minimal perfect hashing (permutations) to reduce collisions.",
    "Rule of thumb: k‚ÄëRR tends to be better when k < e^{Œµ} (empirical ‚Ñì1); otherwise RAPPOR may be better at small Œµ."
  ],
  "conclusion": "Cohort‚Äëstyle hashing combined with k‚ÄëRR yields practical, state‚Äëof‚Äëthe‚Äëart utility for LDP distribution estimation, with regime‚Äëdependent optimality between k‚ÄëRR and RAPPOR and strong performance of O‚ÄëRR in open and closed alphabets.",
  "references_selected": [
    {"authors": "Duchi, Wainwright, Jordan", "year": 2013, "title": "Local privacy and minimax bounds", "note": "high privacy rates"},
    {"authors": "Erlingsson, Pihur, Korolova", "year": 2014, "title": "RAPPOR", "note": "open-source LDP reporting"},
    {"authors": "Kairouz, Oh, Viswanath", "year": 2014, "title": "Extremal mechanisms for LDP", "note": "k‚ÄëRR low‚Äëprivacy optimality"},
    {"authors": "Wang & Carreira‚ÄëPerpi√±√°n", "year": 2013, "title": "Projection onto the probability simplex", "note": "decoder projection"},
    {"authors": "Warner", "year": 1965, "title": "Randomized response", "note": "binary LDP classic"}
  ]
}
